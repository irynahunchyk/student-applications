{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d17037f2-a366-4be4-96c1-d5ee617015a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db15c63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\LNU\\6.1\\Course\\Test3\\Yolov8_main\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dir_path = os.path.dirname(os.path.realpath(\"Test2_main.ipynb\"))\n",
    "print(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5059eee-7340-4580-a86a-ccee0b3988de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"D:/LNU/6.1/Course/Test3/Yolov8_main/yolov8x.pt\")\n",
    "dict_classes = model.model.names\n",
    "print(dict_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "345cc5c0-6196-49ba-8f5f-42c491fcbd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "542636b3-b95b-4073-8a19-1478708979f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = 'https://universe.roboflow.com/ds/CWCXC2q9ru?key=xVHKiMtmmg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f455d2d-fb82-4b85-8e10-382f4209894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = wget.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c00234c7-639d-4544-8c0d-c8025c2834db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/LNU/6.1/Course/Test3/Yolov8_main/Buildings_2.v1i.yolov8.zip\n"
     ]
    }
   ],
   "source": [
    "filename = (\"D:/LNU/6.1/Course/Test3/Yolov8_main/Buildings_2.v1i.yolov8.zip\")\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ad70179-744a-499d-80dd-00712d9f6442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c0613ab-c548-41ee-a5b9-fe0ac77e95b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('D:/LNU/6.1/Course/Test3/Yolov8_main/Buildings_2.v1i.yolov8.zip') as target_file:\n",
    "    target_file.extractall('D:/LNU/6.1/Course/Test3/Yolov8_main/content/building_Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db50d5fe-aade-41a2-bf12-62bb4634bfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bf65ff0-a597-42db-bfa9-8bafae9b0e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\LNU\\6.1\\Course\\Test3\\Yolov8_main\n"
     ]
    }
   ],
   "source": [
    "dir_path = os.path.dirname(os.path.realpath(\"Test2_main.ipynb\"))\n",
    "print(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b71e8303-1b0c-400d-85ff-82138099886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffe479fe-9bba-42c7-a192-3834386a4b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'names': ['building'],\n",
       " 'nc': 1,\n",
       " 'test': 'D:/LNU/6.1/Course/Test3/Yolov8_main/content/building_Data/test/images',\n",
       " 'train': 'D:/LNU/6.1/Course/Test3/Yolov8_main/content/building_Data/train/images',\n",
       " 'val': 'D:/LNU/6.1/Course/Test3/Yolov8_main/content/building_Data/val/images'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = {'train' :  'D:/LNU/6.1/Course/Test3/Yolov8_main/content/building_Data/train/images',\n",
    "        'val' :  'D:/LNU/6.1/Course/Test3/Yolov8_main/content/building_Data/val/images',\n",
    "        'test' :  'D:/LNU/6.1/Course/Test3/Yolov8_main/content/building_Data/test/images',\n",
    "        'nc': 1,\n",
    "        'names': ['building']\n",
    "        }\n",
    "\n",
    "# overwrite the data to the .yaml file\n",
    "with open('D:/LNU/6.1/Course/Test3/Yolov8_main/content/building_Data/building_data.yaml', 'w') as f:\n",
    "    yaml.dump(data, f)\n",
    "\n",
    "# read the content in .yaml file\n",
    "with open('D:/LNU/6.1/Course/Test3/Yolov8_main/content/building_Data/building_data.yaml', 'r') as f:\n",
    "    b_yaml = yaml.safe_load(f)\n",
    "    display(b_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24b4faca-6389-4d24-9ff2-bc0f05fb6eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "print(len(model.names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7d55161-eeea-4969-8be2-03586f1664cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5835, 0.7393, 0.8593],\n",
      "        [0.9225, 0.4744, 0.0767],\n",
      "        [0.7142, 0.6030, 0.7170],\n",
      "        [0.5259, 0.0822, 0.7393],\n",
      "        [0.1648, 0.2156, 0.9934]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e1d0521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 1.9.0+cu111\n",
      "Is CUDA enabled? True\n",
      "1\n",
      "tensor([0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Torch version:\",torch.__version__)\n",
    "\n",
    "print(\"Is CUDA enabled?\",torch.cuda.is_available())\n",
    "\n",
    "print(torch.cuda.device_count())#1 - ok \n",
    "\n",
    "print(torch.zeros(1).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a8ad866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Sep_21_10:41:10_Pacific_Daylight_Time_2022\n",
      "Cuda compilation tools, release 11.8, V11.8.89\n",
      "Build cuda_11.8.r11.8/compiler.31833905_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16b57626-8697-41cd-ace7-b9ed31dbc12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.227 🚀 Python-3.9.0 torch-1.9.0+cu111 CUDA:0 (NVIDIA GeForce RTX 3060, 12287MiB)\n",
      "WARNING ⚠️ Upgrade to torch>=2.0.0 for deterministic training.\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=D:/LNU/6.1/Course/Test3/Yolov8_main/yolov8x.pt, data=D:/LNU/6.1/Course/Test3/Yolov8_main/content/building_Data/data.yaml, epochs=50, patience=50, batch=2, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train58, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train58\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8718931  ultralytics.nn.modules.head.Detect           [1, [320, 640, 640]]          \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary: 365 layers, 68153571 parameters, 68153555 gradients, 258.1 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train58', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "WARNING ⚠️ NMS time limit 0.550s exceeded\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\LNU\\6.1\\Course\\Test3\\Yolov8_main\\content\\building_Data\\train\\labels.cache... 438 images, 0 backgrounds, 0 corrupt: 100%|██████████| 438/438 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\LNU\\6.1\\Course\\Test3\\Yolov8_main\\content\\building_Data\\valid\\labels.cache... 56 images, 0 backgrounds, 0 corrupt: 100%|██████████| 56/56 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train58\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train58\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50       2.9G      1.985      2.422      2.028          8        640: 100%|██████████| 219/219 [00:55<00:00,  3.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258       0.13      0.202       0.08     0.0259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      2.95G      2.274       2.64      2.335          8        640: 100%|██████████| 219/219 [00:53<00:00,  4.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:02<00:00,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.387      0.194      0.172     0.0549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      2.96G      2.217      2.485      2.286          9        640: 100%|██████████| 219/219 [00:53<00:00,  4.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.146      0.178     0.0584     0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      2.97G      2.198       2.53      2.229         15        640: 100%|██████████| 219/219 [00:51<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.401      0.194       0.15     0.0583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      2.97G      2.072      2.329      2.106         17        640: 100%|██████████| 219/219 [00:52<00:00,  4.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.411      0.314      0.343      0.136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      2.97G      2.121       2.29      2.118          9        640: 100%|██████████| 219/219 [00:52<00:00,  4.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.382      0.198       0.19     0.0659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      2.97G       2.05       2.21      2.092         26        640: 100%|██████████| 219/219 [00:53<00:00,  4.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.473      0.442      0.449      0.173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50      2.97G      1.989      2.079      2.005         15        640: 100%|██████████| 219/219 [00:52<00:00,  4.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.605      0.416      0.491      0.203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      2.97G      1.943       2.02      2.014         31        640: 100%|██████████| 219/219 [00:52<00:00,  4.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.415      0.481      0.445      0.202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      2.97G      1.898      1.984      1.984          7        640: 100%|██████████| 219/219 [00:53<00:00,  4.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.527      0.438      0.505      0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      2.97G      1.883      1.939      1.958         24        640: 100%|██████████| 219/219 [00:51<00:00,  4.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.456      0.383      0.371      0.139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50      2.97G      1.944      1.995      1.993         10        640: 100%|██████████| 219/219 [00:53<00:00,  4.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.521      0.512      0.519      0.247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      2.96G      1.911      1.961      1.975         16        640: 100%|██████████| 219/219 [00:52<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:02<00:00,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258       0.56      0.496      0.525      0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      2.96G      1.881       1.88      1.935         18        640: 100%|██████████| 219/219 [00:51<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.555      0.477      0.544      0.243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      2.97G      1.855      1.844      1.928         19        640: 100%|██████████| 219/219 [00:51<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.609      0.538      0.607      0.259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      2.96G      1.888      1.861      1.933          4        640: 100%|██████████| 219/219 [00:52<00:00,  4.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.574      0.535       0.56      0.232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50      2.97G      1.806       1.81      1.897         19        640: 100%|██████████| 219/219 [00:51<00:00,  4.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.653      0.592      0.629      0.294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      2.97G        1.8      1.844      1.889         13        640: 100%|██████████| 219/219 [00:52<00:00,  4.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.634      0.584      0.623      0.293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50      2.97G      1.793      1.793      1.888         10        640: 100%|██████████| 219/219 [00:52<00:00,  4.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.657      0.602      0.655      0.316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50      2.97G      1.781      1.792      1.853          4        640: 100%|██████████| 219/219 [00:52<00:00,  4.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.614      0.616      0.669      0.311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      2.97G      1.753      1.696       1.85         25        640: 100%|██████████| 219/219 [00:52<00:00,  4.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.648      0.649      0.675      0.334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50      2.97G       1.75      1.763       1.88          5        640: 100%|██████████| 219/219 [00:52<00:00,  4.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.665      0.636      0.685      0.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50      2.97G       1.72      1.675      1.837         10        640: 100%|██████████| 219/219 [00:52<00:00,  4.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.682      0.643      0.698      0.319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50      2.97G      1.719      1.661      1.816         10        640: 100%|██████████| 219/219 [00:52<00:00,  4.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.617      0.597      0.656      0.314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50      2.97G      1.703      1.644      1.819         12        640: 100%|██████████| 219/219 [00:53<00:00,  4.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.723      0.659      0.727      0.364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      2.97G      1.738      1.658      1.833         14        640: 100%|██████████| 219/219 [00:52<00:00,  4.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.713      0.674      0.738      0.363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      2.97G      1.676      1.622      1.798          8        640: 100%|██████████| 219/219 [00:52<00:00,  4.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.713      0.624      0.716      0.351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      2.97G      1.673      1.524      1.774          7        640: 100%|██████████| 219/219 [00:52<00:00,  4.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.739      0.651      0.732      0.364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50      2.97G      1.665      1.594      1.781         23        640: 100%|██████████| 219/219 [00:52<00:00,  4.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.647      0.705       0.73      0.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50      2.97G       1.66      1.546      1.774         12        640: 100%|██████████| 219/219 [00:52<00:00,  4.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.727      0.663      0.725      0.353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      2.96G      1.663      1.521      1.788         27        640: 100%|██████████| 219/219 [00:51<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.726      0.655      0.742      0.374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50      2.97G      1.616      1.505      1.743         14        640: 100%|██████████| 219/219 [00:51<00:00,  4.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.764      0.647      0.738      0.377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50      2.97G      1.601      1.491      1.727         28        640: 100%|██████████| 219/219 [00:51<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.689      0.738      0.761      0.396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      2.97G      1.611       1.45      1.731          3        640: 100%|██████████| 219/219 [00:51<00:00,  4.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.702      0.659      0.723      0.366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50      2.97G      1.611       1.47      1.733         15        640: 100%|██████████| 219/219 [00:51<00:00,  4.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.739       0.68      0.762      0.393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      2.96G      1.559      1.401       1.69         23        640: 100%|██████████| 219/219 [00:51<00:00,  4.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.749      0.705      0.774      0.418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50      2.97G      1.564      1.401      1.671         13        640: 100%|██████████| 219/219 [00:51<00:00,  4.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.721      0.713      0.764      0.406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50      2.96G      1.569      1.409      1.702         12        640: 100%|██████████| 219/219 [00:51<00:00,  4.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.748      0.678      0.771      0.397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50      2.97G      1.573      1.437      1.715         27        640: 100%|██████████| 219/219 [00:51<00:00,  4.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.763      0.686      0.774       0.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50      2.97G      1.549      1.363      1.677          9        640: 100%|██████████| 219/219 [00:51<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.815      0.651      0.781      0.411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50      2.96G      1.595      1.343      1.748          8        640: 100%|██████████| 219/219 [00:53<00:00,  4.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258        0.8      0.678      0.791      0.416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50      2.97G      1.558      1.305      1.727         14        640: 100%|██████████| 219/219 [00:52<00:00,  4.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.784      0.677      0.778       0.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      2.97G       1.56      1.269      1.722          5        640: 100%|██████████| 219/219 [00:52<00:00,  4.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.803      0.721      0.804      0.425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50      2.97G       1.53      1.242      1.683         12        640: 100%|██████████| 219/219 [00:52<00:00,  4.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.784      0.718      0.787      0.408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      2.96G      1.529      1.229      1.673          9        640: 100%|██████████| 219/219 [00:51<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.783      0.686      0.807      0.426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      2.97G      1.517      1.211      1.687         11        640: 100%|██████████| 219/219 [00:51<00:00,  4.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.753      0.746      0.811      0.429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      2.97G      1.502      1.196      1.663         13        640: 100%|██████████| 219/219 [00:51<00:00,  4.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.805      0.682      0.795      0.423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50      2.97G      1.477      1.182      1.659         13        640: 100%|██████████| 219/219 [00:51<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.754      0.725      0.793      0.423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50      2.97G      1.497      1.162      1.661         10        640: 100%|██████████| 219/219 [00:51<00:00,  4.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.781      0.721      0.794      0.426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50      2.97G      1.465      1.157      1.667          6        640: 100%|██████████| 219/219 [00:52<00:00,  4.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.717      0.767      0.799      0.434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 0.880 hours.\n",
      "Optimizer stripped from runs\\detect\\train58\\weights\\last.pt, 136.7MB\n",
      "Optimizer stripped from runs\\detect\\train58\\weights\\best.pt, 136.7MB\n",
      "\n",
      "Validating runs\\detect\\train58\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.227 🚀 Python-3.9.0 torch-1.9.0+cu111 CUDA:0 (NVIDIA GeForce RTX 3060, 12287MiB)\n",
      "Model summary (fused): 268 layers, 68124531 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:02<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.717      0.767      0.799      0.434\n",
      "Speed: 1.5ms preprocess, 26.7ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train58\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000013E5D1ABC10>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,\n",
       "            0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.96875,     0.96875,     0.96875,     0.96875,     0.96875,\n",
       "            0.96875,     0.96875,     0.96875,     0.96875,     0.96875,     0.96875,     0.96875,     0.96875,     0.96875,     0.96875,     0.96875,     0.95455,     0.95455,     0.95455,     0.94286,     0.94286,     0.94286,     0.94286,     0.94286,     0.94286,     0.94286,     0.94286,     0.94286,\n",
       "            0.94286,     0.94286,     0.94286,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,\n",
       "             0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,      0.9375,     0.92683,     0.92683,     0.92683,     0.92683,     0.91935,     0.91935,     0.91935,     0.91935,\n",
       "            0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,\n",
       "            0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,\n",
       "            0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,\n",
       "            0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,\n",
       "            0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,\n",
       "            0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91935,\n",
       "            0.91935,     0.91935,     0.91935,     0.91935,     0.91935,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,\n",
       "            0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,     0.91912,\n",
       "            0.91912,     0.91912,      0.9078,      0.9078,      0.9078,      0.9078,      0.9078,      0.9078,      0.9078,      0.9078,      0.9078,      0.9078,      0.9078,     0.90132,     0.90132,     0.90132,     0.90132,     0.90132,     0.90132,     0.90132,     0.90132,     0.90132,     0.90132,\n",
       "            0.90132,     0.90132,     0.90132,     0.90132,     0.90132,     0.90132,     0.90132,     0.90132,     0.90132,     0.90132,     0.90132,     0.90132,     0.90132,     0.90132,     0.90132,     0.90132,     0.90132,     0.90132,     0.90132,     0.90132,     0.90132,     0.90132,     0.90132,\n",
       "            0.90132,     0.90132,      0.8961,      0.8961,      0.8961,      0.8961,     0.89172,     0.89172,     0.89172,     0.89172,     0.89172,     0.89172,     0.89172,     0.89172,     0.89024,     0.89024,     0.89024,     0.89024,     0.89024,     0.89024,     0.89024,     0.89024,     0.89024,\n",
       "            0.89024,     0.89024,     0.89024,     0.89024,     0.89024,     0.89024,     0.89024,     0.89024,     0.89024,     0.89024,     0.89024,     0.89024,     0.89024,     0.89024,      0.8869,      0.8869,      0.8869,      0.8869,      0.8869,      0.8869,      0.8869,      0.8869,      0.8869,\n",
       "             0.8869,      0.8869,     0.85955,     0.85955,     0.85955,     0.85955,     0.85955,     0.85955,     0.85955,     0.85955,     0.85955,     0.85955,     0.85955,     0.85955,     0.85955,     0.85955,     0.85955,     0.85955,     0.85714,     0.85714,     0.85714,     0.85714,     0.85714,\n",
       "            0.85714,     0.85714,     0.85714,     0.85714,     0.85714,     0.85714,     0.85714,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85405,     0.85027,     0.85027,     0.85027,     0.85027,     0.84211,     0.84211,     0.84211,     0.84211,     0.84021,\n",
       "            0.84021,     0.84021,     0.84021,     0.84021,     0.84021,     0.84021,     0.84021,     0.84021,     0.84021,     0.84021,     0.84021,     0.83838,     0.83838,     0.83838,     0.83838,     0.83838,     0.83838,     0.83838,     0.83838,     0.83838,     0.83838,     0.83838,       0.835,\n",
       "              0.835,       0.835,       0.835,     0.83495,     0.83495,     0.83495,     0.83495,     0.83495,     0.83495,     0.83495,     0.83495,     0.83495,     0.83495,     0.83495,     0.83495,     0.83495,     0.83495,     0.83495,     0.83495,     0.83495,     0.83495,     0.83495,     0.81991,\n",
       "            0.81991,     0.81991,     0.81991,     0.81308,     0.81308,     0.81308,     0.81308,     0.80365,     0.80365,     0.80365,     0.80365,     0.80365,     0.80365,     0.80365,     0.80365,     0.78319,     0.78319,     0.78319,     0.78319,     0.77155,     0.77155,     0.77155,     0.77155,\n",
       "            0.77155,     0.77155,     0.77155,     0.77155,     0.75949,     0.75949,     0.75949,     0.75519,     0.75519,     0.75519,     0.75519,     0.75519,     0.75519,     0.75519,     0.75519,      0.7551,      0.7551,      0.7551,      0.7551,      0.7551,      0.7551,      0.7551,      0.7551,\n",
       "             0.7551,      0.7551,      0.7551,      0.7551,     0.75299,     0.75299,     0.75299,     0.75299,     0.75299,     0.75299,     0.75299,     0.75299,     0.75299,     0.75299,     0.75299,     0.75299,     0.75299,     0.75299,     0.75299,     0.75197,     0.75197,     0.75197,     0.75197,\n",
       "            0.75197,     0.75197,     0.75197,     0.75197,     0.75097,     0.75097,     0.75097,     0.75097,     0.75097,     0.75097,     0.75097,     0.75097,     0.74903,     0.74903,     0.74903,     0.74903,     0.74242,     0.74242,     0.74242,     0.74242,     0.74242,     0.74242,     0.74242,\n",
       "            0.72794,     0.72794,     0.72794,     0.72794,     0.72794,     0.72794,     0.72794,     0.72794,      0.7028,      0.7028,      0.7028,      0.7028,      0.7028,      0.7028,      0.7028,      0.7028,      0.7028,      0.7028,      0.7028,      0.7028,         0.7,         0.7,         0.7,\n",
       "                0.7,         0.7,         0.7,         0.7,         0.7,     0.69153,     0.69153,     0.69153,     0.67657,     0.67657,     0.67657,     0.67657,     0.66883,     0.66883,     0.66883,     0.66883,     0.65714,     0.65714,     0.65714,     0.65714,     0.64396,     0.64396,     0.64396,\n",
       "            0.64396,     0.63939,     0.63939,     0.63939,     0.63939,     0.63939,     0.63939,     0.63939,     0.63939,     0.63939,     0.63939,     0.63939,     0.63939,     0.63095,     0.63095,     0.63095,     0.59003,     0.59003,     0.59003,     0.59003,     0.58791,     0.58791,     0.58791,\n",
       "            0.58791,     0.57796,     0.57796,     0.57796,     0.57796,     0.57294,     0.57294,     0.57294,     0.57294,     0.56658,     0.56658,     0.56658,     0.56658,     0.55754,     0.55754,     0.55754,     0.55754,     0.55443,     0.55443,     0.55443,     0.55416,     0.55416,     0.55416,\n",
       "            0.55416,     0.53771,     0.53771,     0.53771,     0.53771,     0.51389,     0.51389,     0.51389,     0.51389,     0.47146,     0.47146,     0.47146,     0.47146,     0.46764,     0.46764,     0.46764,     0.46764,     0.43269,     0.43269,     0.43269,     0.43269,     0.41852,     0.41852,\n",
       "            0.41852,     0.41852,     0.41423,     0.41423,     0.41423,     0.39243,     0.39243,     0.39243,     0.39243,      0.3804,      0.3804,      0.3804,      0.3804,     0.37954,     0.37954,     0.37954,     0.37954,     0.37379,     0.37379,     0.37379,     0.37379,     0.36943,     0.36943,\n",
       "            0.36943,     0.36943,     0.36349,     0.36349,     0.36349,     0.36349,     0.35671,     0.35671,     0.35671,     0.35671,      0.3518,      0.3518,      0.3518,     0.34802,     0.34802,     0.34802,     0.34802,     0.34802,     0.34802,     0.34802,     0.34802,     0.34493,     0.34493,\n",
       "            0.34493,     0.34493,     0.34488,     0.34488,     0.34488,     0.34488,     0.34483,     0.34483,     0.34483,     0.34483,     0.32879,     0.32879,     0.32879,     0.32879,     0.30288,     0.30288,     0.30288,     0.30288,     0.29067,     0.29067,     0.29067,     0.26813,     0.26813,\n",
       "            0.26813,     0.26813,     0.26573,     0.26573,     0.26573,     0.26573,     0.24773,     0.24773,     0.24773,     0.24773,     0.23479,     0.23479,     0.23479,     0.23479,     0.22921,     0.22921,     0.22921,     0.22921,     0.19699,     0.19699,     0.19699,     0.19699,     0.18369,\n",
       "            0.18369,     0.18369,     0.18369,     0.15003,     0.15003,     0.15003,     0.14516,     0.14516,     0.14516,     0.14516,      0.1449,      0.1449,      0.1449,      0.1449,     0.13964,     0.13964,     0.13964,     0.13964,     0.13821,     0.13821,     0.13821,     0.13821,     0.11378,\n",
       "            0.11378,     0.11378,     0.11378,    0.045011,     0.03858,     0.03215,     0.02572,     0.01929,     0.01286,   0.0064301,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.094832,    0.094832,     0.13815,     0.17066,      0.1943,     0.21723,     0.23514,     0.25035,     0.26125,     0.27229,     0.28588,     0.29878,     0.30972,     0.31819,     0.32677,      0.3365,     0.34683,     0.35544,     0.36149,     0.36918,     0.37624,     0.38024,      0.3849,\n",
       "            0.39233,     0.39627,     0.40153,     0.40653,     0.41222,     0.41556,     0.41752,     0.42037,     0.42675,     0.43467,     0.44011,     0.44857,       0.452,     0.45558,     0.45897,     0.46397,     0.46824,     0.47144,     0.47309,     0.47481,     0.47856,     0.48268,     0.48542,\n",
       "            0.48918,     0.49324,     0.49719,     0.50211,       0.502,     0.50148,     0.50445,      0.5051,     0.50612,     0.51009,     0.51044,      0.5132,     0.51569,     0.51747,     0.51934,     0.52344,     0.52401,     0.52727,     0.52984,     0.53231,     0.53191,      0.5352,     0.53807,\n",
       "            0.53938,     0.54286,     0.54264,     0.54434,     0.54561,     0.54937,     0.55279,     0.55542,     0.55805,     0.56191,     0.56234,     0.56551,     0.56781,     0.57177,     0.57489,      0.5782,     0.57957,     0.58112,      0.5817,     0.58459,     0.58748,     0.59064,     0.59262,\n",
       "            0.59395,     0.59479,      0.5969,      0.5999,     0.60302,     0.60369,     0.60705,     0.60754,     0.60628,     0.60943,     0.61012,     0.60936,     0.60974,     0.61143,     0.61362,     0.61417,     0.61519,     0.61679,     0.61753,     0.61809,     0.61947,     0.62063,     0.62156,\n",
       "            0.62435,     0.62926,     0.63184,     0.63277,     0.63459,     0.63728,     0.64036,     0.64133,     0.64173,      0.6432,     0.64466,     0.64636,     0.64842,     0.64954,     0.65092,     0.65181,     0.65463,     0.65876,     0.65949,     0.65902,     0.66141,     0.66371,     0.66585,\n",
       "            0.66621,     0.66657,     0.67023,     0.67164,     0.67068,     0.66955,     0.67041,     0.67288,     0.67499,     0.67609,     0.67682,     0.67829,     0.67938,     0.67968,     0.68177,     0.68161,     0.68284,     0.68432,     0.68593,     0.68709,     0.68611,     0.68672,     0.68802,\n",
       "            0.68751,     0.68699,     0.68648,     0.68761,     0.68894,     0.69003,     0.69155,     0.69264,     0.69324,     0.69376,     0.69575,     0.69742,     0.69836,     0.69939,     0.70113,     0.70154,     0.70196,     0.70245,     0.70296,     0.70456,     0.70693,     0.70744,     0.71061,\n",
       "            0.71175,     0.71233,     0.71432,     0.71536,     0.71665,     0.71707,     0.71749,     0.71584,     0.71264,     0.71143,     0.71241,     0.71325,     0.71481,     0.71582,     0.71395,     0.71722,     0.71838,     0.71941,     0.72086,     0.72044,     0.72203,     0.72333,     0.72456,\n",
       "             0.7253,      0.7261,     0.72686,     0.72752,     0.72646,     0.72965,     0.72992,     0.73018,     0.73045,     0.73072,     0.72882,     0.73138,     0.73236,     0.73334,     0.73416,     0.73484,     0.73673,     0.73721,     0.73768,     0.73756,     0.73726,     0.73696,     0.73666,\n",
       "            0.73635,     0.73605,     0.73575,     0.73624,      0.7373,     0.73785,     0.73844,     0.73909,     0.73986,     0.73655,     0.73703,     0.73751,     0.73834,     0.73795,     0.73602,     0.73496,     0.73305,     0.73321,     0.73385,     0.73441,     0.73489,     0.73529,     0.73569,\n",
       "            0.73621,     0.73759,     0.73806,     0.73853,     0.74025,     0.74041,     0.74056,     0.74071,     0.74087,     0.74102,     0.74117,     0.74133,     0.74148,     0.74372,     0.74474,     0.74532,     0.74707,       0.744,     0.74248,     0.74441,     0.74572,     0.74655,     0.74848,\n",
       "            0.74893,     0.74938,     0.75088,     0.74991,     0.74882,     0.74668,      0.7477,     0.74968,     0.74901,     0.74829,     0.74866,     0.74904,     0.74941,     0.74714,     0.74364,       0.743,     0.74237,     0.74174,     0.74139,     0.74236,     0.74164,     0.74091,     0.74019,\n",
       "            0.73987,     0.73957,     0.73927,     0.73897,     0.73867,     0.73837,     0.73807,     0.73777,     0.73654,     0.73414,     0.73423,     0.73469,     0.73515,      0.7355,     0.73403,     0.73216,     0.72998,      0.7285,      0.7284,       0.729,     0.72924,     0.72829,     0.72734,\n",
       "            0.72481,     0.72567,     0.72631,     0.72691,     0.72622,     0.72495,     0.72555,     0.72616,      0.7285,     0.72925,     0.72972,     0.73019,     0.72949,     0.72576,     0.72617,     0.72658,     0.72732,     0.72866,     0.72922,     0.72978,     0.73112,      0.7295,     0.73038,\n",
       "            0.73127,     0.73204,      0.7326,     0.73317,     0.73383,     0.73453,     0.73523,     0.73593,      0.7365,     0.73678,     0.73707,     0.73736,     0.73765,     0.73793,     0.73534,     0.73432,     0.73333,     0.73276,     0.73318,      0.7336,     0.73403,     0.73455,     0.73513,\n",
       "            0.73571,     0.73633,     0.73533,     0.73477,     0.73535,     0.73593,     0.73665,     0.73745,     0.73596,     0.73591,      0.7371,     0.73818,     0.73979,     0.73996,     0.74013,      0.7403,     0.74048,     0.74065,     0.74082,     0.74099,     0.74116,     0.74133,      0.7402,\n",
       "            0.73864,     0.73805,     0.73746,     0.73687,     0.73628,     0.73556,     0.73462,     0.73368,     0.73291,     0.73231,     0.73172,     0.73113,     0.73053,     0.73013,     0.72976,      0.7294,     0.72903,     0.72867,      0.7283,     0.72793,     0.72847,     0.72697,     0.72713,\n",
       "            0.72506,     0.72446,     0.72385,     0.72324,     0.72264,     0.72178,     0.72081,     0.71985,     0.71976,      0.7199,     0.72004,     0.72017,     0.72031,     0.72045,     0.72059,     0.72073,     0.72087,     0.72101,     0.72115,     0.71824,     0.71773,     0.71722,     0.71672,\n",
       "            0.71621,      0.7157,      0.7145,     0.71304,     0.71332,     0.71414,     0.71407,      0.7138,     0.71353,     0.71326,       0.713,     0.71273,     0.71246,     0.71219,     0.71192,     0.71166,     0.71145,     0.71188,     0.71232,     0.71275,      0.7137,     0.71446,     0.71413,\n",
       "             0.7138,     0.71347,     0.71314,     0.71281,     0.71248,     0.71215,     0.71182,     0.71282,      0.7129,     0.71231,     0.71171,     0.71111,     0.71052,     0.70796,     0.70887,     0.70188,     0.70036,     0.70048,     0.70076,     0.70103,      0.7013,     0.70158,      0.7018,\n",
       "            0.70119,     0.70058,     0.69996,     0.69935,     0.69529,     0.68999,     0.69081,     0.69152,     0.69193,     0.69235,     0.69276,     0.69332,     0.69415,     0.69486,     0.69542,     0.69597,     0.69706,     0.69831,     0.69915,     0.69781,     0.69467,     0.69308,     0.69255,\n",
       "            0.69203,      0.6915,     0.69097,     0.69044,     0.69093,     0.69177,      0.6863,     0.68528,     0.68474,     0.68421,     0.68367,     0.68313,      0.6826,     0.68206,     0.68152,     0.68098,     0.68044,     0.67991,     0.67608,     0.67445,     0.67312,      0.6734,     0.67368,\n",
       "            0.67395,     0.67423,     0.67451,     0.67099,     0.66935,     0.66848,     0.66903,     0.66959,     0.66849,     0.66792,     0.66708,     0.66625,     0.66541,     0.66319,     0.65751,     0.65581,     0.65447,     0.65333,      0.6522,     0.65066,     0.64895,     0.64788,     0.64702,\n",
       "            0.64616,      0.6453,     0.64419,     0.64304,     0.64189,     0.63876,     0.63957,      0.6402,     0.64061,     0.64102,     0.64143,      0.6406,     0.63885,     0.63366,     0.63189,     0.63242,     0.63349,     0.63431,     0.63386,     0.63297,     0.63207,     0.63118,     0.62954,\n",
       "            0.62774,     0.61727,     0.61529,     0.61347,     0.61299,     0.61255,     0.61212,     0.61169,     0.61126,     0.61083,     0.61039,     0.60996,     0.60858,     0.60673,     0.60555,     0.60462,     0.60369,     0.60277,     0.60158,     0.60034,     0.59909,     0.59673,     0.59564,\n",
       "            0.59644,      0.5965,     0.59574,     0.59499,     0.59423,     0.59348,     0.58871,     0.58744,     0.58617,     0.57801,     0.57672,     0.57543,     0.56583,     0.56287,     0.56241,     0.56194,     0.56148,     0.56101,     0.56054,     0.56008,     0.55961,     0.55914,     0.55783,\n",
       "             0.5565,     0.55513,     0.55313,     0.55045,     0.54616,     0.54414,     0.54293,     0.54212,     0.54131,     0.54049,     0.53968,     0.53493,     0.53418,     0.53343,     0.53268,     0.53193,     0.53177,     0.53237,     0.53296,     0.53242,     0.53187,     0.53132,     0.53076,\n",
       "            0.53021,     0.52966,     0.52911,     0.52612,     0.52403,     0.52283,     0.52163,     0.52018,     0.51807,     0.51385,     0.51074,     0.50861,     0.50779,     0.50713,     0.50648,     0.50582,     0.50516,      0.5045,      0.4957,     0.49462,     0.49353,     0.49244,     0.49159,\n",
       "              0.492,     0.49241,     0.49282,     0.49245,     0.49182,      0.4912,     0.49057,     0.48994,     0.48932,     0.48869,     0.48593,     0.48396,     0.48316,     0.48235,     0.48154,     0.48074,     0.47556,     0.47467,     0.47377,     0.47287,     0.47197,     0.47063,     0.46762,\n",
       "            0.46573,     0.46421,      0.4627,     0.45993,      0.4583,     0.45921,     0.45724,     0.45494,     0.45306,     0.45121,     0.44987,     0.44902,     0.44817,     0.44733,     0.44648,     0.44584,     0.44652,      0.4453,     0.44275,     0.44313,     0.44352,     0.44365,     0.44318,\n",
       "            0.44271,     0.44223,     0.44176,     0.44129,     0.44081,     0.44034,     0.43987,     0.43939,     0.43861,     0.43755,      0.4365,     0.43544,     0.43386,     0.42946,     0.42705,     0.42489,     0.42368,     0.42247,     0.42126,     0.41891,     0.41539,     0.41457,     0.41376,\n",
       "            0.41294,     0.41212,      0.4113,      0.4085,     0.40075,     0.39713,     0.39152,     0.38949,     0.38779,     0.38861,      0.3847,     0.38479,     0.38434,      0.3839,     0.38345,       0.383,     0.38255,      0.3821,     0.38165,     0.38121,     0.38076,     0.38031,     0.37769,\n",
       "            0.37374,     0.37113,     0.36879,     0.36669,       0.365,     0.36569,      0.3653,     0.36491,     0.36452,     0.36413,     0.36373,     0.36334,     0.36295,     0.36256,     0.36216,     0.36177,     0.36138,     0.36098,      0.3509,     0.34939,     0.34841,     0.34743,     0.34645,\n",
       "            0.34546,     0.34347,     0.34075,     0.33938,     0.33881,     0.33823,     0.33766,     0.33708,     0.33651,     0.33593,     0.33535,     0.33477,     0.33451,     0.33479,     0.33506,     0.33534,     0.33296,     0.32742,       0.319,     0.31252,     0.31026,     0.30793,     0.30508,\n",
       "            0.30223,     0.29936,     0.29672,     0.29507,     0.29342,     0.29176,     0.28839,     0.28206,     0.27514,     0.27089,     0.26385,     0.26109,     0.25937,     0.25765,     0.25481,     0.24489,      0.2443,     0.24372,     0.24314,     0.24255,     0.24197,     0.24138,      0.2408,\n",
       "            0.24021,     0.23963,     0.23904,     0.23411,     0.23243,     0.23186,      0.2313,     0.23073,     0.23017,      0.2296,     0.22903,     0.22847,      0.2279,     0.22733,     0.22652,     0.22234,     0.22021,     0.21943,     0.21864,     0.21785,     0.21706,     0.21627,     0.21548,\n",
       "            0.21469,     0.21326,     0.21168,     0.21009,     0.20849,     0.20161,     0.20044,     0.19927,      0.1981,     0.19693,     0.18301,     0.18114,     0.17926,     0.17737,     0.16958,     0.16513,      0.1632,     0.16245,      0.1617,     0.16096,     0.16021,     0.15946,     0.15872,\n",
       "            0.15797,     0.15722,     0.14645,     0.14239,     0.13896,     0.13652,     0.13513,     0.13375,     0.13237,     0.13098,     0.12833,     0.12484,     0.12287,      0.1217,     0.12054,     0.11937,     0.11819,     0.11702,     0.11396,     0.11042,     0.10925,     0.10851,     0.10776,\n",
       "            0.10701,     0.10626,     0.10551,     0.10476,     0.10401,     0.10325,    0.093839,    0.090224,    0.087742,    0.085924,    0.084103,    0.082279,    0.079649,    0.076714,    0.065978,    0.061011,    0.057054,    0.053297,     0.05163,    0.050258,    0.048884,    0.047508,     0.04613,\n",
       "           0.043904,    0.040859,    0.037659,    0.032546,    0.029949,    0.028984,    0.028019,    0.027053,    0.026086,    0.025118,    0.024149,    0.023179,    0.020907,    0.018311,    0.015707,    0.014404,    0.013285,    0.012164,    0.011042,    0.009919,   0.0087945,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.049796,    0.049796,    0.074244,    0.093359,     0.10769,     0.12202,     0.13344,     0.14349,     0.15098,      0.1584,     0.16767,     0.17662,     0.18445,      0.1905,     0.19684,     0.20395,     0.21159,     0.21803,      0.2226,     0.22846,     0.23412,     0.23747,     0.24112,\n",
       "            0.24697,     0.25038,     0.25459,     0.25862,     0.26325,     0.26629,      0.2682,     0.27057,     0.27587,     0.28253,     0.28715,     0.29477,     0.29774,     0.30085,     0.30422,     0.30864,     0.31242,     0.31528,     0.31676,      0.3183,     0.32168,     0.32541,      0.3284,\n",
       "            0.33184,     0.33559,     0.33926,     0.34386,     0.34428,     0.34488,     0.34781,     0.34944,     0.35099,     0.35482,     0.35576,     0.35845,     0.36088,     0.36325,      0.3651,     0.36927,     0.37039,     0.37371,     0.37693,     0.37944,     0.38045,     0.38382,     0.38679,\n",
       "            0.38814,     0.39176,     0.39229,     0.39407,      0.3954,     0.39937,       0.403,     0.40579,     0.40861,     0.41276,     0.41367,     0.41798,     0.42094,      0.4253,     0.42877,     0.43247,     0.43496,     0.43671,     0.43737,     0.44064,     0.44394,     0.44756,     0.44984,\n",
       "            0.45137,     0.45233,     0.45478,     0.45827,     0.46192,     0.46271,     0.46667,     0.46725,     0.46671,     0.47064,     0.47145,     0.47171,     0.47216,     0.47419,     0.47683,     0.47749,     0.47873,     0.48066,     0.48156,     0.48225,     0.48394,     0.48534,     0.48649,\n",
       "            0.48992,     0.49599,      0.4992,     0.50036,     0.50264,     0.50603,     0.50992,     0.51116,     0.51304,     0.51492,      0.5168,     0.51899,     0.52165,      0.5231,      0.5249,     0.52606,     0.52973,     0.53516,     0.53613,     0.53677,     0.54022,     0.54329,     0.54617,\n",
       "            0.54665,     0.54714,     0.55208,       0.554,     0.55433,     0.55445,     0.55732,     0.56073,     0.56368,     0.56698,       0.568,     0.57008,     0.57162,     0.57259,     0.57685,      0.5785,     0.58027,     0.58241,     0.58475,     0.58644,     0.58695,     0.58784,     0.58993,\n",
       "            0.58965,     0.58938,      0.5891,     0.59113,     0.59311,     0.59472,     0.59699,     0.59861,     0.59951,     0.60029,     0.60327,     0.60579,     0.60721,     0.60878,     0.61141,     0.61204,     0.61267,     0.61343,      0.6142,     0.61665,     0.62029,     0.62107,     0.62597,\n",
       "            0.62991,     0.63093,     0.63406,     0.63571,     0.63776,     0.63842,     0.63908,     0.63846,     0.63686,      0.6366,     0.63817,     0.63952,     0.64202,     0.64365,     0.64311,     0.64843,     0.65034,     0.65202,     0.65442,     0.65632,     0.65896,     0.66112,     0.66318,\n",
       "            0.66443,     0.66578,     0.66705,     0.66816,     0.66813,     0.67453,     0.67499,     0.67545,      0.6759,     0.67636,     0.67562,     0.68034,     0.68204,     0.68374,     0.68518,     0.68636,     0.68966,     0.69049,     0.69133,     0.69142,     0.69128,     0.69114,       0.691,\n",
       "            0.69086,     0.69073,     0.69059,     0.69177,     0.69365,     0.69462,     0.69566,     0.69681,     0.69954,     0.69843,      0.6993,     0.70016,     0.70166,     0.70234,     0.70147,     0.70099,     0.70013,      0.7019,     0.70308,     0.70411,     0.70499,     0.70573,     0.70646,\n",
       "            0.70742,     0.70998,     0.71085,     0.71173,     0.71492,     0.71521,      0.7155,     0.71578,     0.71607,     0.71636,     0.71664,     0.71693,     0.71722,     0.72142,     0.72335,     0.72443,     0.72775,      0.7266,     0.72604,     0.72974,     0.73225,     0.73386,      0.7376,\n",
       "            0.73847,     0.73935,     0.74226,       0.742,     0.74155,     0.74067,     0.74351,     0.74743,     0.74844,     0.74852,     0.74927,     0.75001,     0.75076,     0.75002,     0.75099,     0.75073,     0.75048,     0.75023,     0.75043,     0.75288,     0.75259,      0.7523,     0.75201,\n",
       "            0.75188,     0.75176,     0.75164,     0.75152,      0.7514,     0.75128,     0.75116,     0.75104,     0.75055,     0.74958,     0.75225,     0.75322,     0.75419,     0.75507,     0.75448,     0.75374,     0.75286,     0.75227,     0.75292,      0.7542,      0.7551,     0.75472,     0.75434,\n",
       "            0.75415,       0.756,      0.7574,     0.75871,     0.75908,     0.75903,     0.76036,     0.76168,     0.76685,     0.76853,     0.76957,     0.77062,     0.77112,     0.77036,     0.77128,     0.77219,     0.77387,     0.77692,     0.77819,     0.77947,     0.78253,     0.78389,     0.78593,\n",
       "              0.788,     0.78977,     0.79109,     0.79242,     0.79396,      0.7956,     0.79724,     0.79889,     0.80022,      0.8009,     0.80158,     0.80226,     0.80294,     0.80363,     0.80277,     0.80242,     0.80208,     0.80215,     0.80316,     0.80418,     0.80519,     0.80645,     0.80785,\n",
       "            0.80925,     0.81277,     0.81244,      0.8126,     0.81403,     0.81546,     0.81722,      0.8192,     0.81934,     0.82119,     0.82418,     0.82688,     0.83092,     0.83136,     0.83179,     0.83223,     0.83266,      0.8331,     0.83353,     0.83397,      0.8344,     0.83484,      0.8346,\n",
       "            0.83414,     0.83396,     0.83379,     0.83361,     0.83344,     0.83322,     0.83294,     0.83266,     0.83243,     0.83225,     0.83207,     0.83189,     0.83171,     0.83159,     0.83148,     0.83137,     0.83126,     0.83115,     0.83104,     0.83093,     0.83476,     0.83548,     0.83811,\n",
       "             0.8375,     0.83732,     0.83714,     0.83696,     0.83679,     0.83653,     0.83624,     0.83596,     0.83619,     0.83657,     0.83695,     0.83732,      0.8377,     0.83807,     0.83845,     0.83883,      0.8392,     0.83958,     0.83995,     0.83933,     0.83918,     0.83903,     0.83888,\n",
       "            0.83873,     0.83858,     0.83823,      0.8378,     0.83943,     0.84169,     0.84204,     0.84196,     0.84189,     0.84181,     0.84173,     0.84165,     0.84157,      0.8415,     0.84142,     0.84134,     0.84137,      0.8426,     0.84382,     0.84504,     0.84772,     0.85023,     0.85013,\n",
       "            0.85004,     0.84995,     0.84986,     0.84977,     0.84968,     0.84958,     0.84949,     0.85262,     0.85394,     0.85378,     0.85362,     0.85345,     0.85329,     0.85259,      0.8565,      0.8552,     0.85478,      0.8555,     0.85632,     0.85714,     0.85796,     0.85878,     0.85954,\n",
       "            0.85938,     0.85922,     0.85905,     0.85889,      0.8578,     0.85685,     0.85938,      0.8616,     0.86288,     0.86417,     0.86545,      0.8672,     0.86979,     0.87205,      0.8738,     0.87555,       0.879,       0.883,     0.88569,     0.88652,     0.88582,     0.88547,     0.88535,\n",
       "            0.88523,     0.88512,       0.885,     0.88488,     0.88691,     0.88967,     0.88902,     0.88879,     0.88867,     0.88856,     0.88844,     0.88832,      0.8882,     0.88808,     0.88796,     0.88784,     0.88773,     0.88761,     0.88675,     0.88638,     0.88623,     0.88719,     0.88816,\n",
       "            0.88912,     0.89009,     0.89105,     0.89092,     0.89056,     0.89102,       0.893,     0.89497,     0.89581,     0.90124,     0.90107,     0.90091,     0.90074,     0.90029,     0.89913,     0.89878,      0.8985,     0.89827,     0.89803,     0.89771,     0.89735,     0.89712,     0.89694,\n",
       "            0.89676,     0.89658,     0.89634,      0.8961,     0.89585,     0.89649,     0.89972,     0.90219,     0.90383,     0.90547,      0.9071,     0.90761,     0.90727,     0.90626,     0.90591,     0.91035,      0.9148,     0.91824,       0.919,     0.91885,      0.9187,     0.91854,     0.91826,\n",
       "            0.91794,     0.91608,     0.91573,      0.9154,     0.91531,     0.91523,     0.91515,     0.91507,     0.91499,     0.91491,     0.91483,     0.91475,      0.9145,     0.91416,     0.91394,     0.91376,     0.91359,     0.91342,     0.91319,     0.91296,     0.91272,     0.91227,     0.91362,\n",
       "            0.91739,     0.91929,     0.91916,     0.91902,     0.91889,     0.91875,     0.91789,     0.91766,     0.91743,     0.91592,     0.91568,     0.91543,     0.91359,     0.91302,     0.91293,     0.91283,     0.91274,     0.91265,     0.91256,     0.91247,     0.91237,     0.91228,     0.91202,\n",
       "            0.91175,     0.91148,     0.91107,     0.91053,     0.90965,     0.90923,     0.90898,      0.9088,     0.90863,     0.90846,     0.90829,     0.90728,     0.90712,     0.90696,      0.9068,     0.90663,     0.90805,     0.91156,     0.91506,     0.91498,     0.91487,     0.91476,     0.91465,\n",
       "            0.91454,     0.91443,     0.91432,     0.91372,     0.91329,     0.91304,      0.9128,      0.9125,     0.91206,     0.91117,     0.91051,     0.91005,     0.90987,     0.90973,     0.90959,     0.90944,      0.9093,     0.90916,      0.9072,     0.90695,     0.90671,     0.90646,      0.9067,\n",
       "             0.9095,     0.91229,     0.91509,     0.91569,     0.91556,     0.91543,      0.9153,     0.91517,     0.91504,      0.9149,     0.91432,      0.9139,     0.91372,     0.91355,     0.91338,      0.9132,     0.91207,     0.91187,     0.91167,     0.91147,     0.91127,     0.91097,     0.91028,\n",
       "            0.90985,      0.9095,     0.90915,      0.9085,     0.91063,     0.91785,     0.91817,     0.91767,     0.91727,     0.91687,     0.91657,     0.91639,      0.9162,     0.91601,     0.91582,     0.91646,     0.92218,     0.92648,      0.9283,     0.93169,     0.93508,     0.93748,      0.9374,\n",
       "            0.93731,     0.93723,     0.93715,     0.93707,     0.93699,     0.93691,     0.93683,     0.93675,     0.93661,     0.93643,     0.93624,     0.93606,     0.93578,     0.93499,     0.93456,     0.93416,     0.93394,     0.93371,     0.93349,     0.93305,     0.93238,     0.93222,     0.93206,\n",
       "            0.93191,     0.93175,     0.93159,     0.93104,     0.94257,     0.94195,     0.94098,     0.94062,     0.94143,     0.95116,     0.96381,     0.96872,     0.96868,     0.96863,     0.96859,     0.96854,      0.9685,     0.96845,     0.96841,     0.96837,     0.96832,     0.96828,     0.96801,\n",
       "            0.96761,     0.96734,     0.96709,     0.96687,     0.96975,     0.98304,     0.98302,     0.98299,     0.98297,     0.98295,     0.98293,      0.9829,     0.98288,     0.98286,     0.98284,     0.98282,     0.98279,     0.98277,     0.98218,     0.98209,     0.98203,     0.98196,      0.9819,\n",
       "            0.98184,     0.98172,     0.98155,     0.98146,     0.98142,     0.98138,     0.98134,     0.98131,     0.98127,     0.98123,     0.98119,     0.98116,     0.98288,     0.98771,     0.99255,     0.99738,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.99225,     0.99225,     0.99225,     0.99225,     0.99225,     0.98837,     0.98837,     0.98062,     0.96899,     0.96899,     0.96899,     0.96899,     0.96512,     0.96512,     0.96124,     0.96124,     0.96124,     0.96124,     0.96124,     0.96124,     0.95736,     0.95349,     0.95349,\n",
       "            0.95349,     0.94961,     0.94961,     0.94961,     0.94961,     0.94574,     0.94186,     0.94186,     0.94186,     0.94186,     0.94186,     0.93798,     0.93798,     0.93798,     0.93411,     0.93411,     0.93411,     0.93411,     0.93411,     0.93411,     0.93411,     0.93411,     0.93023,\n",
       "            0.93023,     0.93023,     0.93023,     0.93023,     0.92636,      0.9186,     0.91778,     0.91085,     0.90698,     0.90698,      0.9031,      0.9031,      0.9031,     0.89922,     0.89922,     0.89861,     0.89535,     0.89506,     0.89147,     0.89147,     0.88372,     0.88372,     0.88372,\n",
       "            0.88372,     0.88372,     0.87984,     0.87984,     0.87984,     0.87984,     0.87984,     0.87984,     0.87984,     0.87984,      0.8778,     0.87402,     0.87209,     0.87209,     0.87209,     0.87209,     0.86822,     0.86822,     0.86822,     0.86822,     0.86822,     0.86822,     0.86822,\n",
       "            0.86822,     0.86822,     0.86822,     0.86822,     0.86822,     0.86822,     0.86822,     0.86822,     0.86496,     0.86434,     0.86434,     0.86047,     0.86047,     0.86047,     0.86047,     0.86047,     0.86047,     0.86047,     0.86047,     0.86047,     0.86047,     0.86047,     0.86047,\n",
       "            0.86047,     0.86047,     0.86047,     0.86047,     0.86047,     0.86047,     0.86047,     0.86047,     0.85659,     0.85659,     0.85659,     0.85659,     0.85659,     0.85659,     0.85659,     0.85659,     0.85659,     0.85659,     0.85659,     0.85336,     0.85271,     0.85271,     0.85271,\n",
       "            0.85271,     0.85271,     0.85271,     0.85271,     0.84884,     0.84496,     0.84109,     0.84109,     0.84109,     0.83721,     0.83721,     0.83721,     0.83721,     0.83602,     0.83333,     0.82946,     0.82946,     0.82946,     0.82946,     0.82946,     0.82558,     0.82558,     0.82524,\n",
       "             0.8243,     0.82337,     0.82243,     0.82171,     0.82171,     0.82171,     0.82171,     0.82171,     0.82171,     0.82171,     0.82171,     0.82171,     0.82171,     0.82171,     0.82171,     0.82171,     0.82171,     0.82171,     0.82171,     0.82171,     0.82171,     0.82171,     0.82171,\n",
       "            0.81804,     0.81783,     0.81783,     0.81783,     0.81783,     0.81783,     0.81783,     0.81454,      0.8089,      0.8062,      0.8062,      0.8062,      0.8062,      0.8062,     0.80233,     0.80233,     0.80233,     0.80233,     0.80233,     0.79845,     0.79845,     0.79845,     0.79845,\n",
       "            0.79845,     0.79845,     0.79845,     0.79845,     0.79594,     0.79457,     0.79457,     0.79457,     0.79457,     0.79457,     0.79113,      0.7907,      0.7907,      0.7907,      0.7907,      0.7907,      0.7907,      0.7907,      0.7907,     0.79031,     0.78979,     0.78928,     0.78877,\n",
       "            0.78826,     0.78774,     0.78723,     0.78682,     0.78682,     0.78682,     0.78682,     0.78682,     0.78511,     0.77907,     0.77907,     0.77907,     0.77907,     0.77736,     0.77415,     0.77238,     0.76922,     0.76744,     0.76744,     0.76744,     0.76744,     0.76744,     0.76744,\n",
       "            0.76744,     0.76744,     0.76744,     0.76744,     0.76744,     0.76744,     0.76744,     0.76744,     0.76744,     0.76744,     0.76744,     0.76744,     0.76744,     0.76744,     0.76744,     0.76744,     0.76744,     0.76226,     0.75969,     0.75969,     0.75969,     0.75969,     0.75969,\n",
       "            0.75969,     0.75969,     0.75969,       0.758,     0.75623,     0.75278,     0.75194,     0.75194,     0.74958,     0.74806,     0.74806,     0.74806,     0.74806,     0.74428,     0.73643,     0.73543,     0.73444,     0.73345,     0.73256,     0.73213,       0.731,     0.72986,     0.72873,\n",
       "            0.72823,     0.72777,      0.7273,     0.72683,     0.72636,      0.7259,     0.72543,     0.72496,     0.72304,     0.71932,     0.71705,     0.71705,     0.71705,     0.71693,     0.71466,     0.71179,     0.70845,     0.70618,     0.70543,     0.70543,      0.7051,     0.70365,     0.70221,\n",
       "            0.69767,     0.69767,     0.69767,     0.69767,     0.69609,      0.6938,      0.6938,      0.6938,      0.6938,      0.6938,      0.6938,      0.6938,     0.69212,     0.68605,     0.68605,     0.68605,     0.68605,     0.68605,     0.68605,     0.68605,     0.68605,     0.68217,     0.68217,\n",
       "            0.68217,     0.68217,     0.68217,     0.68217,     0.68217,     0.68217,     0.68217,     0.68217,     0.68217,     0.68217,     0.68217,     0.68217,     0.68217,     0.68217,     0.67836,     0.67687,     0.67543,     0.67442,     0.67442,     0.67442,     0.67442,     0.67442,     0.67442,\n",
       "            0.67442,     0.67303,     0.67159,     0.67054,     0.67054,     0.67054,     0.67054,     0.67054,     0.66799,     0.66667,     0.66667,     0.66667,     0.66667,     0.66667,     0.66667,     0.66667,     0.66667,     0.66667,     0.66667,     0.66667,     0.66667,     0.66667,     0.66498,\n",
       "            0.66276,     0.66193,     0.66109,     0.66025,     0.65942,     0.65839,     0.65706,     0.65574,     0.65464,     0.65381,     0.65297,     0.65213,      0.6513,     0.65073,     0.65022,     0.64971,     0.64919,     0.64868,     0.64817,     0.64766,     0.64618,     0.64341,     0.64211,\n",
       "            0.63924,      0.6384,     0.63757,     0.63673,      0.6359,     0.63471,     0.63338,     0.63206,     0.63178,     0.63178,     0.63178,     0.63178,     0.63178,     0.63178,     0.63178,     0.63178,     0.63178,     0.63178,     0.63178,     0.62768,     0.62699,      0.6263,     0.62561,\n",
       "            0.62492,     0.62423,      0.6226,     0.62062,     0.62016,     0.62016,     0.61986,      0.6195,     0.61914,     0.61878,     0.61842,     0.61805,     0.61769,     0.61733,     0.61697,     0.61661,     0.61628,     0.61628,     0.61628,     0.61628,     0.61628,     0.61608,     0.61564,\n",
       "             0.6152,     0.61476,     0.61431,     0.61387,     0.61343,     0.61299,     0.61255,      0.6124,     0.61185,     0.61106,     0.61026,     0.60947,     0.60867,     0.60528,     0.60465,     0.59518,     0.59319,     0.59302,     0.59302,     0.59302,     0.59302,     0.59302,     0.59298,\n",
       "            0.59218,     0.59139,     0.59059,      0.5898,     0.58455,     0.57752,     0.57752,     0.57752,     0.57752,     0.57752,     0.57752,     0.57752,     0.57752,     0.57752,     0.57752,     0.57752,     0.57752,     0.57752,     0.57752,     0.57534,     0.57137,     0.56937,     0.56871,\n",
       "            0.56805,     0.56739,     0.56672,     0.56606,     0.56589,     0.56589,     0.55887,      0.5576,     0.55694,     0.55627,     0.55561,     0.55495,     0.55429,     0.55363,     0.55296,      0.5523,     0.55164,     0.55098,     0.54629,     0.54431,     0.54264,     0.54264,     0.54264,\n",
       "            0.54264,     0.54264,     0.54264,     0.53815,     0.53617,     0.53488,     0.53488,     0.53488,     0.53318,     0.53056,     0.52957,     0.52857,     0.52758,     0.52495,     0.51824,     0.51625,     0.51468,     0.51335,     0.51203,     0.51024,     0.50826,     0.50701,     0.50602,\n",
       "            0.50503,     0.50403,     0.50276,     0.50144,     0.50011,     0.49612,     0.49612,     0.49612,     0.49612,     0.49612,     0.49612,     0.49498,       0.493,     0.48713,     0.48515,      0.4845,      0.4845,      0.4845,     0.48376,     0.48276,     0.48177,     0.48078,     0.47895,\n",
       "            0.47696,     0.46545,      0.4633,     0.46131,     0.46079,     0.46032,     0.45985,     0.45939,     0.45892,     0.45845,     0.45798,     0.45752,     0.45603,     0.45404,     0.45277,     0.45178,     0.45079,     0.44979,     0.44853,      0.4472,     0.44588,     0.44337,     0.44186,\n",
       "            0.44186,     0.44148,     0.44069,     0.43989,      0.4391,      0.4383,     0.43331,     0.43199,     0.43067,     0.42223,     0.42091,     0.41959,     0.40982,     0.40684,     0.40638,     0.40591,     0.40544,     0.40497,     0.40451,     0.40404,     0.40357,     0.40311,     0.40179,\n",
       "            0.40046,      0.3991,     0.39711,     0.39445,     0.39023,     0.38824,     0.38706,     0.38627,     0.38547,     0.38468,     0.38388,     0.37927,     0.37855,     0.37783,      0.3771,     0.37638,     0.37597,     0.37597,     0.37597,     0.37544,     0.37491,     0.37438,     0.37385,\n",
       "            0.37333,      0.3728,     0.37227,     0.36941,     0.36742,     0.36629,     0.36515,     0.36378,     0.36179,     0.35782,     0.35491,     0.35292,     0.35217,     0.35156,     0.35094,     0.35033,     0.34972,     0.34911,     0.34102,     0.34003,     0.33903,     0.33804,     0.33721,\n",
       "            0.33721,     0.33721,     0.33721,     0.33678,     0.33622,     0.33565,     0.33508,     0.33451,     0.33395,     0.33338,      0.3309,     0.32913,     0.32841,     0.32768,     0.32696,     0.32624,     0.32163,     0.32084,     0.32004,     0.31925,     0.31846,     0.31727,     0.31462,\n",
       "            0.31296,     0.31164,     0.31031,      0.3079,      0.3062,      0.3062,     0.30442,     0.30244,     0.30083,     0.29924,     0.29808,     0.29736,     0.29664,     0.29592,      0.2952,     0.29457,     0.29457,     0.29308,      0.2907,      0.2907,      0.2907,     0.29058,     0.29019,\n",
       "            0.28979,     0.28939,       0.289,      0.2886,      0.2882,      0.2878,     0.28741,     0.28701,     0.28635,     0.28547,     0.28459,     0.28371,     0.28239,     0.27874,     0.27676,     0.27498,     0.27399,       0.273,       0.272,     0.27008,     0.26722,     0.26656,      0.2659,\n",
       "            0.26523,     0.26457,     0.26391,     0.26165,     0.25447,      0.2516,     0.24718,     0.24559,     0.24419,     0.24419,     0.24031,     0.24008,     0.23973,     0.23939,     0.23904,     0.23869,     0.23835,       0.238,     0.23766,     0.23731,     0.23697,     0.23662,     0.23462,\n",
       "             0.2316,     0.22961,     0.22784,     0.22625,     0.22481,     0.22463,     0.22433,     0.22404,     0.22375,     0.22345,     0.22316,     0.22286,     0.22257,     0.22227,     0.22198,     0.22169,     0.22139,      0.2211,     0.21361,      0.2125,     0.21177,     0.21105,     0.21033,\n",
       "            0.20961,     0.20815,     0.20616,     0.20516,     0.20475,     0.20433,     0.20391,     0.20349,     0.20307,     0.20265,     0.20224,     0.20182,     0.20155,     0.20155,     0.20155,     0.20155,     0.19973,     0.19576,     0.18977,      0.1852,     0.18361,     0.18199,        0.18,\n",
       "            0.17801,     0.17603,      0.1742,     0.17307,     0.17193,      0.1708,     0.16849,     0.16418,     0.15951,     0.15667,     0.15197,     0.15014,     0.14901,     0.14787,     0.14601,     0.13953,     0.13915,     0.13877,     0.13839,     0.13801,     0.13764,     0.13726,     0.13688,\n",
       "             0.1365,     0.13612,     0.13574,     0.13257,     0.13149,     0.13113,     0.13077,     0.13041,     0.13005,     0.12969,     0.12933,     0.12897,      0.1286,     0.12824,     0.12772,     0.12507,     0.12373,     0.12323,     0.12274,     0.12224,     0.12174,     0.12125,     0.12075,\n",
       "            0.12025,     0.11936,     0.11837,     0.11737,     0.11638,     0.11211,     0.11138,     0.11066,     0.10994,     0.10922,     0.10072,    0.099589,    0.098453,    0.097318,    0.092644,    0.089996,    0.088847,    0.088406,    0.087964,    0.087523,    0.087081,     0.08664,    0.086199,\n",
       "           0.085757,    0.085316,    0.079013,    0.076653,    0.074667,    0.073258,    0.072464,    0.071669,    0.070874,     0.07008,    0.068562,    0.066575,    0.065457,    0.064795,    0.064133,    0.063471,    0.062809,    0.062146,    0.060422,    0.058435,    0.057784,    0.057365,    0.056947,\n",
       "           0.056529,    0.056111,    0.055693,    0.055274,    0.054856,    0.054438,    0.049229,    0.047243,    0.045884,    0.044891,    0.043898,    0.042904,    0.041476,    0.039887,    0.034114,    0.031466,    0.029365,    0.027378,    0.026499,    0.025777,    0.025054,    0.024332,     0.02361,\n",
       "           0.022445,    0.020856,    0.019191,    0.016542,    0.015202,    0.014705,    0.014209,    0.013712,    0.013215,    0.012719,    0.012222,    0.011726,    0.010564,   0.0092399,   0.0079155,   0.0072545,   0.0066869,   0.0061194,   0.0055518,   0.0049842,   0.0044167,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: 0.47020783899683904\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.43366])\n",
       "names: {0: 'building'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.7169311790165575, 'metrics/recall(B)': 0.7674418604651163, 'metrics/mAP50(B)': 0.799170604617163, 'metrics/mAP50-95(B)': 0.4336564205945808, 'fitness': 0.47020783899683904}\n",
       "save_dir: WindowsPath('runs/detect/train58')\n",
       "speed: {'preprocess': 1.4997337545667375, 'inference': 26.660629681178502, 'loss': 0.0, 'postprocess': 2.071653093610491}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(data='D:/LNU/6.1/Course/Test3/Yolov8_main/content/building_Data/data.yaml', epochs=50, batch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d08087-7a5e-4552-96cb-39e08a05dd6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b74c9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLO(\n",
       "  (model): DetectionModel(\n",
       "    (model): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(3, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv(\n",
       "        (conv): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(400, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Conv(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (4): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (4): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (5): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Conv(\n",
       "        (conv): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (6): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (4): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (5): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Conv(\n",
       "        (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (8): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): SPPF(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (10): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (11): Concat()\n",
       "      (12): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (14): Concat()\n",
       "      (15): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(800, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): Conv(\n",
       "        (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (17): Concat()\n",
       "      (18): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): Conv(\n",
       "        (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (20): Concat()\n",
       "      (21): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): Detect(\n",
       "        (cv2): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(320, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(640, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(640, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (cv3): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(320, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(320, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(320, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (dfl): DFL(\n",
       "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba9b9ec6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'torch._C.Generator' object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:/LNU/6.1/Course/Test3/Yolov8_main/saved_models/yolov8_50_epoch_v1.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ultralytics\\utils\\patches.py:77\u001b[0m, in \u001b[0;36mtorch_save\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickle_module\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m     76\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickle_module\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pickle  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _torch_save(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\serialization.py:379\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m--> 379\u001b[0m         \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    381\u001b[0m _legacy_save(obj, opened_file, pickle_module, pickle_protocol)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\serialization.py:484\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    482\u001b[0m pickler \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mPickler(data_buf, protocol\u001b[38;5;241m=\u001b[39mpickle_protocol)\n\u001b[0;32m    483\u001b[0m pickler\u001b[38;5;241m.\u001b[39mpersistent_id \u001b[38;5;241m=\u001b[39m persistent_id\n\u001b[1;32m--> 484\u001b[0m \u001b[43mpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    485\u001b[0m data_value \u001b[38;5;241m=\u001b[39m data_buf\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m    486\u001b[0m zip_file\u001b[38;5;241m.\u001b[39mwrite_record(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, data_value, \u001b[38;5;28mlen\u001b[39m(data_value))\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot pickle 'torch._C.Generator' object"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.save(model,\"D:/LNU/6.1/Course/Test3/Yolov8_main/saved_models/yolov8_50_epoch_v1.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68ff25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.jit.load(\"D:/LNU/6.1/Course/Test3/Yolov8_main/saved_models/yolov8_50_epoch_v2.pt\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e81b54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf17fc52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49e895bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n"
     ]
    }
   ],
   "source": [
    "# model_test = YOLO(\"D:/LNU/6.1/Course/Test3/Yolov8_main/yolov8x.pt\")\n",
    "# dict_classes = model_test.model.names\n",
    "# print(dict_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f434ebc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78029794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model_test,\"D:/LNU/6.1/Course/Test3/Yolov8_main/saved_models/yolov8_50_epoch_v1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56132dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'names': ['person',\n",
       "  'bicycle',\n",
       "  'car',\n",
       "  'motorcycle',\n",
       "  'airplane',\n",
       "  'bus',\n",
       "  'train',\n",
       "  'truck',\n",
       "  'boat',\n",
       "  'traffic light',\n",
       "  'fire hydrant',\n",
       "  'stop sign',\n",
       "  'parking meter',\n",
       "  'bench',\n",
       "  'bird',\n",
       "  'cat',\n",
       "  'dog',\n",
       "  'horse',\n",
       "  'sheep',\n",
       "  'cow',\n",
       "  'elephant',\n",
       "  'bear',\n",
       "  'zebra',\n",
       "  'giraffe',\n",
       "  'backpack',\n",
       "  'umbrella',\n",
       "  'handbag',\n",
       "  'tie',\n",
       "  'suitcase',\n",
       "  'frisbee',\n",
       "  'skis',\n",
       "  'snowboard',\n",
       "  'sports ball',\n",
       "  'kite',\n",
       "  'baseball bat',\n",
       "  'baseball glove',\n",
       "  'skateboard',\n",
       "  'surfboard',\n",
       "  'tennis racket',\n",
       "  'bottle',\n",
       "  'wine glass',\n",
       "  'cup',\n",
       "  'fork',\n",
       "  'knife',\n",
       "  'spoon',\n",
       "  'bowl',\n",
       "  'banana',\n",
       "  'apple',\n",
       "  'sandwich',\n",
       "  'orange',\n",
       "  'broccoli',\n",
       "  'carrot',\n",
       "  'hot dog',\n",
       "  'pizza',\n",
       "  'donut',\n",
       "  'cake',\n",
       "  'chair',\n",
       "  'couch',\n",
       "  'potted plant',\n",
       "  'bed',\n",
       "  'dining table',\n",
       "  'toilet',\n",
       "  'tv',\n",
       "  'laptop',\n",
       "  'mouse',\n",
       "  'remote',\n",
       "  'keyboard',\n",
       "  'cell phone',\n",
       "  'microwave',\n",
       "  'oven',\n",
       "  'toaster',\n",
       "  'sink',\n",
       "  'refrigerator',\n",
       "  'book',\n",
       "  'clock',\n",
       "  'vase',\n",
       "  'scissors',\n",
       "  'teddy bear',\n",
       "  'hair drier',\n",
       "  'toothbrush',\n",
       "  'building'],\n",
       " 'nc': 81,\n",
       " 'test': 'D:/LNU/6.1/Course/Test3/Yolov8_main/content/building_Data/test/images',\n",
       " 'train': 'D:/LNU/6.1/Course/Test3/Yolov8_main/content/building_Data/train/images',\n",
       " 'val': 'D:/LNU/6.1/Course/Test3/Yolov8_main/content/building_Data/val/images'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import yaml\n",
    "# data = {'train' :  'D:/LNU/6.1/Course/Test3/Yolov8_main/content/building_Data/train/images',\n",
    "#         'val' :  'D:/LNU/6.1/Course/Test3/Yolov8_main/content/building_Data/val/images',\n",
    "#         'test' :  'D:/LNU/6.1/Course/Test3/Yolov8_main/content/building_Data/test/images',\n",
    "#         'nc': 81,\n",
    "#         'names': [\"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\", \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\",\"building\"]\n",
    "#         }\n",
    "\n",
    "# # overwrite the data to the .yaml file\n",
    "# with open('D:/LNU/6.1/Course/Test3/Yolov8_main/content/building_Data/test.yaml', 'w') as f:\n",
    "#     yaml.dump(data, f)\n",
    "\n",
    "# # read the content in .yaml file\n",
    "# with open('D:/LNU/6.1/Course/Test3/Yolov8_main/content/building_Data/test.yaml', 'r') as f:\n",
    "#     b_yaml = yaml.safe_load(f)\n",
    "#     display(b_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a97ef6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "# print(len(model_test.names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4389774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.227 🚀 Python-3.9.0 torch-1.9.0+cu111 CUDA:0 (NVIDIA GeForce RTX 3060, 12287MiB)\n",
      "WARNING ⚠️ Upgrade to torch>=2.0.0 for deterministic training.\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=D:/LNU/6.1/Course/Test3/Yolov8_main/yolov8x.pt, data=D:/LNU/6.1/Course/Test3/Yolov8_main/content/building_Data/test.yaml, epochs=50, patience=50, batch=2, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train48, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train48\n",
      "Overriding model.yaml nc=80 with nc=81\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8795971  ultralytics.nn.modules.head.Detect           [81, [320, 640, 640]]         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary: 365 layers, 68230611 parameters, 68230595 gradients, 258.6 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train48', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\LNU\\6.1\\Course\\Test3\\Yolov8_main\\content\\building_Data\\train\\labels.cache... 438 images, 0 backgrounds, 0 corrupt: 100%|██████████| 438/438 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\LNU\\6.1\\Course\\Test3\\Yolov8_main\\content\\building_Data\\valid\\labels.cache... 56 images, 0 backgrounds, 0 corrupt: 100%|██████████| 56/56 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train48\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000118, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train48\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      2.94G      1.758      2.743      1.839          8        640: 100%|██████████| 219/219 [00:55<00:00,  3.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:02<00:00,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.729      0.674      0.719      0.365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      2.99G      1.563      1.808      1.649          8        640: 100%|██████████| 219/219 [00:53<00:00,  4.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.734      0.686      0.759      0.427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      3.01G      1.496      1.494      1.584          9        640: 100%|██████████| 219/219 [00:53<00:00,  4.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.728      0.736      0.784      0.417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      3.01G      1.518      1.391      1.599         15        640: 100%|██████████| 219/219 [00:53<00:00,  4.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.759      0.747      0.808      0.425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      3.01G      1.514      1.304      1.602         17        640: 100%|██████████| 219/219 [00:53<00:00,  4.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.843      0.725      0.834      0.471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      3.01G      1.482      1.301      1.564          9        640: 100%|██████████| 219/219 [00:52<00:00,  4.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.799      0.752      0.827      0.422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      3.01G      1.469      1.213      1.589         26        640: 100%|██████████| 219/219 [00:51<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.745      0.806       0.83      0.446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50      3.01G      1.445      1.084       1.53         15        640: 100%|██████████| 219/219 [00:51<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.801      0.764      0.844      0.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      3.01G      1.406      1.071      1.537         31        640: 100%|██████████| 219/219 [00:52<00:00,  4.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.771      0.811      0.836      0.454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      3.01G      1.399       1.01      1.544          7        640: 100%|██████████| 219/219 [00:51<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.851      0.795      0.858      0.471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      3.01G      1.374     0.9833      1.523         24        640: 100%|██████████| 219/219 [00:51<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.873      0.769       0.86      0.463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50      3.01G      1.362      0.984      1.515         10        640: 100%|██████████| 219/219 [00:51<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258       0.82      0.783       0.85      0.478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      3.01G      1.348     0.9575      1.513         16        640: 100%|██████████| 219/219 [00:52<00:00,  4.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.825      0.784      0.842      0.463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      3.01G      1.328      0.917      1.479         18        640: 100%|██████████| 219/219 [00:51<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.804      0.833      0.864      0.496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      3.01G      1.282     0.8588      1.448         19        640: 100%|██████████| 219/219 [00:53<00:00,  4.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.836      0.841      0.868      0.479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      3.01G      1.303     0.8835      1.448          4        640: 100%|██████████| 219/219 [00:53<00:00,  4.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.848      0.823      0.881      0.495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50      3.01G      1.238     0.8454       1.41         19        640: 100%|██████████| 219/219 [00:53<00:00,  4.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.864      0.812      0.878      0.507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      3.01G      1.238     0.8481      1.434         13        640: 100%|██████████| 219/219 [00:53<00:00,  4.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.839       0.83      0.871      0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50      3.01G      1.228      0.836      1.419         10        640: 100%|██████████| 219/219 [00:52<00:00,  4.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.847      0.816      0.857      0.485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50      3.01G      1.231     0.8554      1.408          4        640: 100%|██████████| 219/219 [00:51<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.806      0.795      0.843      0.472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      3.01G       1.21     0.8186      1.407         25        640: 100%|██████████| 219/219 [00:51<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.819      0.822      0.852       0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50      3.01G      1.216     0.8108      1.428          5        640: 100%|██████████| 219/219 [00:51<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258       0.84      0.826       0.87      0.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50      3.01G      1.181     0.7649       1.39         10        640: 100%|██████████| 219/219 [00:51<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.812      0.853      0.857      0.492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50      3.01G      1.203     0.7795      1.407         10        640: 100%|██████████| 219/219 [00:51<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.804      0.806      0.849      0.489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50      3.01G      1.137     0.7454      1.366         12        640: 100%|██████████| 219/219 [00:51<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.822      0.841      0.845      0.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      3.02G      1.136     0.7285      1.361         14        640: 100%|██████████| 219/219 [00:51<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.835      0.826      0.858       0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      3.01G      1.135     0.7317      1.375          8        640: 100%|██████████| 219/219 [00:51<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.859      0.826      0.864      0.496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      3.01G      1.124     0.6779      1.339          7        640: 100%|██████████| 219/219 [00:52<00:00,  4.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.844      0.841      0.855      0.481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50      3.01G      1.117     0.7282      1.354         23        640: 100%|██████████| 219/219 [00:52<00:00,  4.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.824      0.815      0.846      0.489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50      3.01G      1.099     0.7068      1.339         12        640: 100%|██████████| 219/219 [00:52<00:00,  4.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.812      0.855       0.87      0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      3.01G      1.085     0.6863      1.344         27        640: 100%|██████████| 219/219 [00:52<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.859      0.826      0.873       0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50      3.01G      1.045     0.6701      1.314         14        640: 100%|██████████| 219/219 [00:52<00:00,  4.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.804       0.86      0.869        0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50      3.01G       1.06     0.6832      1.321         28        640: 100%|██████████| 219/219 [00:51<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.808      0.884      0.881      0.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      3.01G      1.058     0.6846      1.306          3        640: 100%|██████████| 219/219 [00:52<00:00,  4.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.839      0.829      0.858      0.489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50      3.01G      1.061     0.6758      1.305         15        640: 100%|██████████| 219/219 [00:51<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.822      0.814      0.863      0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      3.01G      1.017     0.6254      1.273         23        640: 100%|██████████| 219/219 [00:52<00:00,  4.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.813      0.861      0.866      0.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50      3.02G       1.03     0.6245      1.273         13        640: 100%|██████████| 219/219 [00:51<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.831      0.864      0.871      0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50      3.01G      1.001     0.6195      1.278         12        640: 100%|██████████| 219/219 [00:51<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.849       0.83      0.869      0.495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50      3.02G          1      0.618      1.276         27        640: 100%|██████████| 219/219 [00:51<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.859       0.81       0.86      0.511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50      3.01G      0.988     0.5942      1.253          9        640: 100%|██████████| 219/219 [00:51<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.855      0.826      0.867      0.511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50      3.01G     0.9424     0.5154      1.233          8        640: 100%|██████████| 219/219 [00:52<00:00,  4.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258       0.86      0.802      0.866      0.509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50      3.01G     0.9079      0.482      1.205         14        640: 100%|██████████| 219/219 [00:52<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.844      0.817      0.865      0.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      3.01G     0.9158     0.4758       1.21          5        640: 100%|██████████| 219/219 [00:52<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.822      0.841      0.856      0.508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50      3.01G     0.8923     0.4726      1.195         12        640: 100%|██████████| 219/219 [00:52<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.855      0.798      0.853      0.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      3.01G     0.8849     0.4696      1.182          9        640: 100%|██████████| 219/219 [00:52<00:00,  4.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.833      0.833      0.858      0.507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      3.01G     0.8592     0.4528      1.185         11        640: 100%|██████████| 219/219 [00:52<00:00,  4.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.846      0.822      0.856      0.507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      3.01G     0.8564      0.444      1.169         13        640: 100%|██████████| 219/219 [00:51<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.862       0.81      0.856       0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50         3G     0.8439     0.4445       1.17         13        640: 100%|██████████| 219/219 [00:51<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.842      0.822      0.855      0.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50      3.01G     0.8473     0.4395      1.159         10        640: 100%|██████████| 219/219 [00:51<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.855      0.799      0.852      0.502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50      3.01G     0.8576     0.4421      1.191          6        640: 100%|██████████| 219/219 [00:51<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:01<00:00,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.845      0.814      0.854      0.508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 0.819 hours.\n",
      "Optimizer stripped from runs\\detect\\train48\\weights\\last.pt, 136.9MB\n",
      "Optimizer stripped from runs\\detect\\train48\\weights\\best.pt, 136.9MB\n",
      "\n",
      "Validating runs\\detect\\train48\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.227 🚀 Python-3.9.0 torch-1.9.0+cu111 CUDA:0 (NVIDIA GeForce RTX 3060, 12287MiB)\n",
      "Model summary (fused): 268 layers, 68201571 parameters, 0 gradients, 257.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 14/14 [00:02<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         56        258      0.811      0.883      0.881      0.512\n",
      "                person         56        258      0.811      0.883      0.881      0.512\n",
      "Speed: 1.5ms preprocess, 28.4ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train48\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x00000247B93A80A0>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,\n",
       "            0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,\n",
       "            0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.98387,     0.96875,     0.96875,     0.96875,     0.96875,     0.95652,     0.95652,     0.95652,     0.95652,     0.95652,     0.95652,     0.95652,     0.95652,     0.95652,     0.95652,     0.95652,     0.95652,\n",
       "            0.95652,     0.95652,     0.95652,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,\n",
       "             0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,\n",
       "             0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,\n",
       "             0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,\n",
       "             0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,\n",
       "             0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,\n",
       "             0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,      0.9537,     0.94595,     0.94595,     0.94595,     0.94595,     0.94595,     0.94595,     0.94595,     0.94595,     0.94118,     0.94118,     0.94118,     0.94118,     0.94118,     0.94118,     0.94118,\n",
       "            0.94118,     0.94118,     0.94118,     0.94118,     0.94118,     0.94118,     0.94118,     0.94118,     0.94118,     0.94118,     0.94118,     0.94118,     0.94118,     0.94118,     0.94118,     0.94118,     0.94118,     0.94118,     0.94118,     0.94118,     0.93056,     0.93056,     0.93056,\n",
       "            0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,\n",
       "            0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,\n",
       "            0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,\n",
       "            0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.93056,     0.92308,     0.92308,     0.92308,     0.92308,     0.92308,     0.92308,     0.92308,     0.92308,     0.92308,     0.92308,\n",
       "            0.92308,     0.92308,     0.92308,     0.92308,     0.92308,     0.92308,     0.92308,     0.92308,     0.92308,     0.92308,     0.92308,     0.92308,     0.92308,     0.92308,     0.92308,     0.92308,     0.92308,     0.92308,     0.92308,     0.92308,     0.92308,     0.92308,     0.92308,\n",
       "            0.92308,     0.92308,     0.92308,     0.92308,     0.92308,     0.92308,     0.91824,     0.91824,     0.91824,     0.91824,     0.91824,     0.91824,     0.91824,     0.91824,     0.91515,     0.91515,     0.91515,     0.91515,     0.91515,     0.91515,     0.91515,     0.91515,     0.91515,\n",
       "            0.91515,     0.91515,     0.91515,     0.91515,     0.91515,     0.91515,     0.91515,     0.91515,     0.91515,     0.91515,     0.91279,     0.91279,     0.91279,     0.91279,     0.91279,     0.91279,     0.91279,     0.91279,     0.91279,     0.91279,     0.91279,     0.91279,     0.91279,\n",
       "            0.91279,     0.91279,     0.91279,     0.91279,     0.91279,     0.91279,     0.91279,     0.91279,     0.91279,     0.91279,      0.9096,      0.9096,      0.9096,      0.9096,      0.9096,      0.9096,      0.9096,      0.9096,      0.9096,      0.9096,      0.9096,      0.9096,      0.9096,\n",
       "             0.9096,      0.9096,      0.9096,     0.90503,     0.90503,     0.90503,     0.90503,     0.90374,     0.90374,     0.90374,     0.90374,     0.90374,     0.90374,     0.90374,     0.90374,     0.90374,     0.90374,     0.90374,     0.90374,     0.90374,     0.90374,     0.90374,     0.90374,\n",
       "            0.90374,     0.90374,     0.90374,     0.90374,     0.90374,     0.90374,     0.90374,     0.90374,     0.90374,     0.90374,     0.90374,         0.9,         0.9,         0.9,         0.9,         0.9,         0.9,         0.9,         0.9,     0.89744,     0.89744,     0.89744,     0.89744,\n",
       "            0.89744,     0.89744,     0.89744,     0.89744,     0.89744,     0.89744,     0.89744,     0.89744,     0.89744,     0.89744,     0.89744,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,\n",
       "            0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,\n",
       "            0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.89048,     0.88479,     0.88479,     0.88479,     0.88479,     0.88479,     0.88479,     0.88479,     0.88479,     0.88479,     0.88479,     0.88479,\n",
       "            0.88479,     0.88479,     0.88479,     0.88479,     0.88479,     0.88479,     0.88479,     0.88479,     0.87892,     0.87892,     0.87892,     0.87892,     0.87892,     0.87892,     0.87892,     0.87892,     0.87892,     0.87892,     0.87892,     0.87892,     0.87892,     0.87892,     0.87892,\n",
       "            0.87168,     0.87168,     0.87168,     0.87168,     0.87124,     0.87124,     0.87124,     0.87124,     0.87124,     0.87124,     0.87124,     0.87124,     0.87124,     0.87124,     0.87124,     0.87124,     0.87124,     0.87124,     0.87124,     0.87124,     0.87124,     0.87124,     0.87124,\n",
       "            0.87124,     0.87124,     0.87124,     0.87124,     0.87124,     0.86441,     0.86441,     0.86441,     0.86134,     0.86134,     0.86134,     0.86134,     0.85656,     0.85656,     0.85656,     0.85656,     0.85656,     0.85656,     0.85656,     0.85656,     0.85656,     0.85656,     0.85656,\n",
       "            0.85656,     0.85656,     0.85656,     0.85656,     0.85656,      0.8502,      0.8502,      0.8502,      0.8502,     0.84739,     0.84739,     0.84739,     0.84739,     0.84462,     0.84462,     0.84462,      0.8419,      0.8419,      0.8419,      0.8419,     0.83984,     0.83984,     0.83984,\n",
       "            0.83984,     0.83984,     0.83984,     0.83984,     0.83984,     0.83846,     0.83846,     0.83846,     0.83846,     0.83846,     0.83846,     0.83846,     0.83846,     0.83846,     0.83846,     0.83846,     0.83846,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,\n",
       "            0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81588,     0.81588,\n",
       "            0.81588,     0.81588,     0.81362,     0.81362,     0.81362,     0.81139,     0.81139,     0.81139,     0.81139,     0.80634,     0.80634,     0.80634,     0.80634,      0.8042,      0.8042,      0.8042,      0.8042,     0.74277,     0.74277,     0.74277,     0.74277,     0.73885,     0.73885,\n",
       "            0.73885,     0.73885,     0.71692,     0.71692,     0.71692,     0.71692,      0.7156,      0.7156,      0.7156,      0.7156,     0.70149,     0.70149,     0.70149,     0.69822,     0.69822,     0.69822,     0.69822,     0.67521,     0.67521,     0.67521,     0.67521,     0.66667,     0.66667,\n",
       "            0.66667,     0.66667,     0.66022,     0.66022,     0.66022,     0.66022,     0.65753,     0.65753,     0.65753,     0.65753,     0.62924,     0.62924,     0.62924,     0.62924,     0.60804,     0.60804,     0.60804,     0.60804,     0.60448,     0.60448,     0.60448,     0.54709,     0.54709,\n",
       "            0.54709,     0.54709,     0.54324,     0.54324,     0.54324,     0.54324,     0.47582,     0.47582,     0.47582,     0.47582,     0.45826,     0.45826,     0.45826,     0.45826,         0.4,         0.4,         0.4,         0.4,     0.38725,     0.38725,     0.38725,     0.38725,     0.31211,\n",
       "            0.31211,     0.31211,     0.31211,     0.22173,     0.22173,     0.22173,     0.21338,     0.21338,     0.21338,     0.21338,     0.18994,     0.18994,     0.18994,     0.18994,     0.15815,     0.14982,      0.1415,     0.13318,     0.12485,     0.11653,     0.10821,    0.099882,    0.091558,\n",
       "           0.083235,    0.074911,    0.066588,    0.058264,    0.049941,    0.041617,    0.033294,     0.02497,    0.016647,   0.0083235,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.27681,     0.27681,     0.37431,     0.43232,     0.46747,     0.49385,     0.52096,     0.53945,     0.55707,     0.56857,      0.5814,     0.59382,     0.60393,     0.61055,     0.61812,     0.62648,      0.6347,     0.64169,     0.64513,     0.65194,     0.65949,     0.66551,     0.67081,\n",
       "            0.67343,     0.67855,     0.68236,     0.68296,      0.6845,     0.68538,     0.68849,     0.68946,     0.69228,     0.69277,     0.69658,     0.69936,     0.70169,      0.7061,      0.7081,     0.70932,     0.71103,     0.71206,     0.71437,     0.71778,     0.71917,     0.71968,     0.72165,\n",
       "            0.72593,     0.72805,     0.72911,      0.7314,     0.73254,     0.73327,       0.734,     0.73616,     0.73568,     0.73488,     0.73475,     0.73541,      0.7376,      0.7361,     0.73621,      0.7366,     0.73699,     0.73722,     0.73745,     0.73768,      0.7379,     0.73813,     0.73985,\n",
       "            0.74277,     0.74444,     0.74732,     0.74844,     0.75183,     0.75029,       0.751,      0.7523,     0.75452,     0.75952,     0.76094,     0.76146,     0.76212,     0.76351,     0.76473,     0.76599,     0.76937,     0.76981,     0.77025,     0.77015,     0.76953,     0.76891,      0.7687,\n",
       "            0.76933,      0.7698,     0.77001,     0.77022,     0.77042,     0.77063,     0.77083,     0.77048,     0.76907,     0.76982,     0.77293,     0.77203,      0.7726,     0.77318,     0.77368,     0.77417,     0.77472,      0.7754,     0.77774,     0.77658,     0.77699,      0.7774,     0.77845,\n",
       "            0.78056,     0.78111,     0.78204,      0.7832,     0.78399,     0.78478,     0.78688,     0.78768,     0.78894,      0.7912,     0.79194,     0.79015,     0.79136,     0.79175,     0.79214,     0.79253,     0.79191,     0.79115,     0.79059,     0.79083,     0.79108,     0.79132,     0.79156,\n",
       "            0.79181,     0.79204,     0.79228,     0.79251,     0.79275,     0.79298,     0.79322,     0.79491,     0.79525,      0.7956,     0.79597,     0.79667,     0.79872,     0.79942,     0.79988,     0.79921,     0.79853,     0.79889,     0.79864,     0.79909,     0.79954,     0.79999,     0.80025,\n",
       "            0.80051,     0.80077,     0.80103,     0.80128,     0.80318,     0.80385,     0.80569,     0.80595,      0.8062,     0.80646,     0.80672,     0.80838,     0.80869,       0.809,     0.80932,     0.80963,      0.8104,     0.81058,      0.8094,     0.81058,     0.81098,     0.81138,     0.81179,\n",
       "            0.81094,     0.81034,     0.81139,     0.81179,     0.81218,     0.81257,      0.8131,     0.81372,     0.81425,     0.81454,     0.81484,     0.81514,     0.81543,     0.81576,     0.81615,     0.81653,     0.81691,      0.8173,     0.81768,     0.81807,     0.81845,       0.819,     0.81956,\n",
       "            0.82013,     0.82071,     0.82128,     0.82185,     0.82243,     0.82299,     0.82354,     0.82409,     0.82466,     0.82524,     0.82581,     0.82637,     0.82692,     0.82762,     0.82873,     0.82984,     0.83149,      0.8322,     0.83264,     0.83308,     0.83341,     0.83359,     0.83378,\n",
       "            0.83396,     0.83414,     0.83432,      0.8345,     0.83469,     0.83489,     0.83525,      0.8356,     0.83596,     0.83631,     0.83683,     0.83737,      0.8379,     0.83811,     0.83832,     0.83854,     0.83875,     0.83896,     0.83917,     0.83939,     0.83985,     0.84035,     0.84086,\n",
       "            0.84116,     0.84143,     0.84169,     0.84195,     0.84222,     0.84248,     0.84269,     0.84289,      0.8431,      0.8433,     0.84351,     0.84371,     0.84391,      0.8455,     0.84527,     0.84504,     0.84481,     0.84458,     0.84435,     0.84412,     0.84389,     0.84366,     0.84348,\n",
       "            0.84362,     0.84376,     0.84391,     0.84405,     0.84419,     0.84433,     0.84447,     0.84462,     0.84476,      0.8449,     0.84495,     0.84451,     0.84408,     0.84364,      0.8432,     0.84291,     0.84301,      0.8431,      0.8432,     0.84329,     0.84339,     0.84348,     0.84358,\n",
       "            0.84367,     0.84377,     0.84387,     0.84396,     0.84406,     0.84415,     0.84425,     0.84434,     0.84444,      0.8453,     0.84597,     0.84579,      0.8456,     0.84542,     0.84524,     0.84505,     0.84487,     0.84469,      0.8445,     0.84432,     0.84414,     0.84395,     0.84399,\n",
       "            0.84422,     0.84445,     0.84468,     0.84491,     0.84514,     0.84537,     0.84457,      0.8433,     0.84419,     0.84483,     0.84472,      0.8446,     0.84449,     0.84438,     0.84427,     0.84416,     0.84404,     0.84393,     0.84382,     0.84371,     0.84359,     0.84348,     0.84337,\n",
       "            0.84326,     0.84315,     0.84303,     0.84292,     0.84281,      0.8427,     0.84313,     0.84357,       0.844,     0.84421,       0.844,      0.8438,      0.8436,      0.8434,      0.8432,     0.84299,     0.84279,     0.84259,     0.84239,     0.84218,     0.84141,      0.8403,     0.83976,\n",
       "            0.83952,     0.83928,     0.83904,     0.83879,     0.83855,     0.83831,     0.83807,     0.83782,     0.83768,     0.83759,      0.8375,      0.8374,     0.83731,     0.83722,     0.83713,     0.83704,     0.83695,     0.83686,     0.83677,     0.83668,     0.83659,      0.8365,      0.8364,\n",
       "            0.83631,     0.83622,     0.83613,     0.83604,     0.83595,     0.83586,     0.83577,     0.83568,     0.83558,     0.83542,     0.83518,     0.83494,     0.83471,     0.83447,     0.83423,     0.83399,     0.83376,     0.83352,     0.83338,     0.83359,      0.8338,     0.83401,     0.83422,\n",
       "            0.83443,     0.83464,     0.83485,     0.83476,     0.83453,     0.83429,     0.83406,     0.83383,      0.8336,     0.83336,     0.83313,      0.8329,     0.83261,     0.83204,     0.83147,      0.8309,     0.83055,     0.83083,     0.83111,      0.8314,     0.83168,     0.83196,     0.83224,\n",
       "            0.83251,     0.83278,     0.83305,     0.83332,      0.8336,     0.83378,     0.83395,     0.83411,     0.83427,     0.83444,      0.8346,     0.83476,     0.83493,     0.83509,     0.83686,     0.83694,     0.83702,     0.83711,     0.83719,     0.83727,     0.83736,     0.83744,     0.83752,\n",
       "            0.83761,     0.83769,     0.83777,     0.83786,     0.83794,     0.83803,     0.83811,     0.83819,     0.83828,     0.83836,     0.83844,     0.83878,     0.83919,     0.83961,     0.84002,     0.84044,     0.84085,     0.84127,     0.84168,     0.83909,      0.8387,     0.83832,     0.83794,\n",
       "            0.83755,     0.83645,     0.83529,     0.83425,     0.83386,     0.83347,     0.83308,     0.83269,      0.8323,     0.83229,     0.83312,     0.83362,     0.83352,     0.83341,      0.8333,      0.8332,     0.83309,     0.83298,     0.83288,     0.83277,     0.83266,     0.83256,     0.83245,\n",
       "            0.83234,     0.83224,     0.83213,     0.83202,     0.83192,     0.83181,      0.8317,      0.8316,     0.83149,     0.83138,     0.83175,     0.83216,     0.83258,       0.833,     0.83112,     0.83154,     0.83196,     0.83005,     0.83019,     0.83033,     0.83047,     0.83061,     0.83075,\n",
       "            0.83089,     0.83104,     0.83118,     0.83132,     0.83146,      0.8316,     0.83146,     0.83086,     0.83027,     0.82968,     0.82945,     0.82962,     0.82978,     0.82995,     0.83012,     0.83029,     0.83046,     0.83063,      0.8308,     0.83097,     0.83163,     0.83247,     0.83236,\n",
       "            0.83197,     0.83157,     0.83117,     0.83077,     0.83037,     0.82994,      0.8295,     0.82907,     0.82863,      0.8282,     0.82734,     0.82613,     0.82529,     0.82469,     0.82408,     0.82348,     0.82359,     0.82401,     0.82444,     0.82486,     0.82529,     0.82572,     0.82614,\n",
       "            0.82657,     0.82607,     0.82546,     0.82486,     0.82425,     0.82473,     0.82522,      0.8257,     0.82521,     0.82399,     0.82407,     0.82492,     0.82533,     0.82551,     0.82569,     0.82587,     0.82605,     0.82623,     0.82641,      0.8266,     0.82678,     0.82639,     0.82516,\n",
       "            0.82153,     0.82029,     0.81954,     0.81928,     0.81902,     0.81876,      0.8185,     0.81823,     0.81797,     0.81771,     0.81745,     0.81247,      0.8129,     0.81333,     0.81376,     0.81188,     0.81274,     0.81433,     0.81264,     0.81134,     0.81006,     0.80961,     0.80919,\n",
       "            0.80876,     0.80833,     0.80791,     0.80516,     0.80632,     0.80759,      0.8063,     0.80558,     0.80511,     0.80464,     0.80417,      0.8037,     0.80317,     0.80252,     0.80187,     0.80122,     0.80072,     0.80043,     0.80014,     0.79985,     0.79956,     0.79927,     0.79898,\n",
       "            0.79869,      0.7984,     0.79782,     0.79707,     0.79632,     0.79595,     0.79682,     0.79751,     0.79776,     0.79801,     0.79826,     0.79851,     0.79876,     0.79901,     0.79597,     0.79465,     0.79332,     0.79199,     0.79098,     0.79021,     0.78945,     0.78869,     0.78792,\n",
       "            0.78716,     0.78639,     0.78488,     0.78335,     0.78258,      0.7818,     0.78103,     0.77784,     0.77735,     0.77685,     0.77635,     0.77586,     0.77522,     0.77444,     0.77366,     0.77287,     0.77209,      0.7713,     0.77052,     0.77167,     0.77128,     0.77088,     0.77049,\n",
       "            0.77009,      0.7697,      0.7693,     0.76971,     0.77029,     0.77086,     0.77171,     0.77258,     0.77088,     0.76902,     0.76171,     0.76258,     0.76333,     0.76239,     0.76144,     0.75935,     0.75792,     0.75658,     0.75562,     0.75466,     0.75357,     0.75213,     0.75083,\n",
       "            0.74986,      0.7489,     0.74471,     0.74275,     0.73997,     0.74024,     0.74051,     0.74077,     0.74104,     0.74131,     0.74056,     0.73908,     0.73691,     0.73625,     0.73558,     0.73492,     0.72999,     0.72898,     0.72797,     0.72367,     0.72162,     0.71398,     0.71243,\n",
       "            0.71278,     0.71336,     0.71393,     0.71193,     0.70984,     0.70473,     0.70403,     0.70333,     0.70262,     0.70192,     0.69894,     0.69951,     0.70008,     0.69869,     0.69698,     0.69644,      0.6959,     0.69537,     0.69483,     0.69429,     0.69413,     0.69452,      0.6949,\n",
       "            0.69528,     0.69563,     0.69455,     0.69348,     0.68928,     0.68881,     0.68835,     0.68788,     0.68741,     0.68694,     0.68648,     0.68235,     0.68015,     0.67865,     0.67732,     0.67242,     0.67018,     0.66465,     0.66608,     0.66471,     0.66335,     0.65772,     0.65204,\n",
       "            0.64978,     0.64838,     0.64698,     0.64499,     0.64265,      0.6403,      0.6371,     0.63092,      0.6254,      0.6245,     0.62359,     0.62269,     0.62123,     0.61881,     0.61367,      0.6122,     0.61072,     0.60924,     0.60772,     0.60406,     0.60157,     0.59623,     0.59321,\n",
       "            0.59126,     0.59391,     0.59238,     0.59084,     0.58856,     0.57868,     0.57711,     0.57554,     0.56817,     0.56846,     0.56148,     0.56193,     0.56238,     0.56283,     0.56088,     0.55489,     0.55217,     0.55064,     0.55005,     0.54947,     0.54888,      0.5483,     0.54771,\n",
       "            0.54712,     0.54396,     0.53575,     0.53156,     0.52435,     0.51783,      0.5164,     0.51497,     0.51236,     0.50866,     0.50576,     0.50356,     0.50138,     0.49919,     0.49704,     0.49557,      0.4941,     0.49258,     0.49081,     0.48903,      0.4831,      0.4816,      0.4801,\n",
       "            0.47183,     0.46727,     0.46553,     0.46438,     0.46323,     0.46208,     0.45533,     0.45301,     0.44655,     0.44467,     0.44127,     0.43186,     0.42833,     0.41873,     0.41056,     0.40809,     0.40504,     0.39823,     0.39571,     0.39317,     0.39064,     0.38568,     0.38491,\n",
       "            0.38071,     0.38113,     0.37813,     0.37015,     0.36805,     0.36594,     0.36065,     0.35539,     0.35182,     0.34822,     0.34462,     0.34099,      0.3308,     0.32436,     0.31881,     0.31694,     0.31506,     0.31209,       0.307,      0.3032,     0.28644,     0.27656,     0.26936,\n",
       "            0.26177,     0.26085,     0.25992,       0.259,     0.25807,     0.25714,     0.25046,      0.2464,     0.23779,     0.23603,     0.23426,     0.22409,       0.206,      0.2028,     0.19392,     0.18742,     0.18236,     0.18017,     0.17797,     0.17395,     0.16924,     0.16702,     0.16479,\n",
       "            0.15023,     0.14297,     0.14126,     0.13954,     0.13782,     0.12843,     0.11655,     0.11514,     0.11373,     0.11231,      0.1109,      0.1093,     0.10727,     0.10523,     0.10319,     0.10228,     0.10153,     0.10077,     0.10002,    0.099264,    0.098509,    0.097752,    0.096995,\n",
       "           0.096238,     0.08821,    0.087092,    0.085973,    0.084853,    0.083731,    0.082608,    0.081003,    0.078073,    0.075133,    0.065366,    0.062884,    0.060396,    0.058652,    0.056987,    0.055319,    0.053648,    0.051546,    0.049029,    0.046505,    0.037776,    0.035224,    0.032664,\n",
       "           0.027912,    0.020337,    0.016437,    0.013749,    0.011508,   0.0092608,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.16115,     0.16115,     0.23196,     0.27823,     0.30803,     0.33182,     0.35677,     0.37434,     0.39217,     0.40436,     0.41746,     0.43039,     0.44109,     0.44819,     0.45728,     0.46649,     0.47663,     0.48456,     0.48849,     0.49634,     0.50516,     0.51226,     0.51856,\n",
       "             0.5217,     0.52787,      0.5325,     0.53323,     0.53511,     0.53618,     0.54001,     0.54247,     0.54596,     0.54788,     0.55265,     0.55616,     0.55912,     0.56473,      0.5673,     0.56887,     0.57107,      0.5724,      0.5754,     0.57983,     0.58165,     0.58231,      0.5849,\n",
       "            0.59054,     0.59335,     0.59477,     0.59782,     0.59934,     0.60032,      0.6013,      0.6042,     0.60412,     0.60372,      0.6039,      0.6048,     0.60794,     0.60716,     0.60751,     0.60803,     0.60856,     0.60888,     0.60919,      0.6095,     0.60981,     0.61012,     0.61248,\n",
       "            0.61649,     0.61879,     0.62278,     0.62434,     0.62908,     0.62868,     0.62968,     0.63151,     0.63464,     0.64176,     0.64378,     0.64453,     0.64546,     0.64746,     0.64923,     0.65105,     0.65593,     0.65657,     0.65722,     0.65739,     0.65709,     0.65679,      0.6569,\n",
       "            0.65783,     0.65852,     0.65882,     0.65912,     0.65942,     0.65972,     0.66002,     0.65999,     0.65932,     0.66051,      0.6651,     0.66579,     0.66665,      0.6675,     0.66825,     0.66899,     0.66981,     0.67082,     0.67433,     0.67468,      0.6753,     0.67592,     0.67751,\n",
       "            0.68072,     0.68155,     0.68297,     0.68474,     0.68595,     0.68716,     0.69039,     0.69162,     0.69357,     0.69706,     0.69822,     0.69769,     0.69959,      0.7002,     0.70081,     0.70142,      0.7012,     0.70087,     0.70067,     0.70106,     0.70144,     0.70183,     0.70221,\n",
       "            0.70259,     0.70297,     0.70333,      0.7037,     0.70407,     0.70444,     0.70481,     0.70749,     0.70804,     0.70858,     0.70918,     0.71028,     0.71356,     0.71467,     0.71555,     0.71526,     0.71497,     0.71674,     0.71829,     0.71902,     0.71975,     0.72048,     0.72091,\n",
       "            0.72132,     0.72174,     0.72216,     0.72258,     0.72567,     0.72677,     0.72979,     0.73021,     0.73063,     0.73104,     0.73146,      0.7342,     0.73472,     0.73524,     0.73575,     0.73627,     0.73755,     0.73861,      0.7385,     0.74047,     0.74114,     0.74182,     0.74249,\n",
       "            0.74236,     0.74275,     0.74452,     0.74518,     0.74584,      0.7465,      0.7474,     0.74845,     0.74933,     0.74984,     0.75034,     0.75084,     0.75134,     0.75191,     0.75256,     0.75321,     0.75386,     0.75452,     0.75517,     0.75583,     0.75649,     0.75742,     0.75839,\n",
       "            0.75937,     0.76035,     0.76133,     0.76232,     0.76331,     0.76429,     0.76524,     0.76619,     0.76716,     0.76816,     0.76916,     0.77013,     0.77109,     0.77229,     0.77423,     0.77618,     0.77907,     0.78031,     0.78109,     0.78186,     0.78245,     0.78277,     0.78309,\n",
       "            0.78341,     0.78374,     0.78406,     0.78438,      0.7847,     0.78506,     0.78569,     0.78632,     0.78695,     0.78758,      0.7885,     0.78947,      0.7904,     0.79078,     0.79116,     0.79154,     0.79191,     0.79229,     0.79267,     0.79305,     0.79388,     0.79478,     0.79568,\n",
       "            0.79623,      0.7967,     0.79717,     0.79765,     0.79812,     0.79859,     0.79896,     0.79933,      0.7997,     0.80007,     0.80044,      0.8008,     0.80117,     0.80417,     0.80409,     0.80402,     0.80394,     0.80387,      0.8038,     0.80372,     0.80365,     0.80357,     0.80354,\n",
       "             0.8038,     0.80406,     0.80432,     0.80457,     0.80483,     0.80509,     0.80535,      0.8056,     0.80586,     0.80612,     0.80632,     0.80618,     0.80604,      0.8059,     0.80576,      0.8057,     0.80588,     0.80605,     0.80623,      0.8064,     0.80658,     0.80675,     0.80693,\n",
       "             0.8071,     0.80728,     0.80745,     0.80763,      0.8078,     0.80797,     0.80815,     0.80832,      0.8085,     0.81009,     0.81137,     0.81132,     0.81126,      0.8112,     0.81114,     0.81109,     0.81103,     0.81097,     0.81091,     0.81086,      0.8108,     0.81074,     0.81094,\n",
       "            0.81136,     0.81179,     0.81221,     0.81264,     0.81306,     0.81349,     0.81335,     0.81296,     0.81464,     0.81587,     0.81584,     0.81581,     0.81577,     0.81574,      0.8157,     0.81567,     0.81563,      0.8156,     0.81556,     0.81553,     0.81549,     0.81546,     0.81542,\n",
       "            0.81539,     0.81536,     0.81532,     0.81529,     0.81525,     0.81522,     0.81603,     0.81684,     0.81766,     0.81816,      0.8181,     0.81804,     0.81797,     0.81791,     0.81785,     0.81779,     0.81773,     0.81767,      0.8176,     0.81754,     0.81731,     0.81696,      0.8168,\n",
       "            0.81673,     0.81665,     0.81658,      0.8165,     0.81643,     0.81635,     0.81628,      0.8162,     0.81616,     0.81613,      0.8161,     0.81607,     0.81605,     0.81602,     0.81599,     0.81596,     0.81593,     0.81591,     0.81588,     0.81585,     0.81582,     0.81579,     0.81577,\n",
       "            0.81574,     0.81571,     0.81568,     0.81565,     0.81562,      0.8156,     0.81557,     0.81554,     0.81551,     0.81546,     0.81539,     0.81531,     0.81524,     0.81517,     0.81509,     0.81502,     0.81495,     0.81487,     0.81491,     0.81531,     0.81571,     0.81611,     0.81651,\n",
       "            0.81691,     0.81731,     0.81771,      0.8178,     0.81772,     0.81765,     0.81758,     0.81751,     0.81744,     0.81737,      0.8173,     0.81722,     0.81714,     0.81696,     0.81679,     0.81661,     0.81662,     0.81717,     0.81771,     0.81826,     0.81881,     0.81935,     0.81989,\n",
       "            0.82042,     0.82095,     0.82147,       0.822,     0.82253,     0.82289,     0.82321,     0.82353,     0.82385,     0.82417,     0.82449,     0.82481,     0.82513,     0.82545,      0.8289,     0.82907,     0.82923,      0.8294,     0.82956,     0.82972,     0.82989,     0.83005,     0.83022,\n",
       "            0.83038,     0.83055,     0.83071,     0.83087,     0.83104,      0.8312,     0.83137,     0.83153,     0.83169,     0.83186,     0.83202,     0.83269,     0.83351,     0.83432,     0.83514,     0.83596,     0.83678,     0.83761,     0.83843,     0.83773,     0.83763,     0.83752,     0.83741,\n",
       "             0.8373,     0.83981,     0.83949,      0.8392,     0.83909,     0.83898,     0.83887,     0.83877,     0.83866,      0.8391,      0.8408,     0.84189,     0.84186,     0.84183,      0.8418,     0.84177,     0.84174,     0.84171,     0.84168,     0.84165,     0.84162,     0.84159,     0.84157,\n",
       "            0.84154,     0.84151,     0.84148,     0.84145,     0.84142,     0.84139,     0.84136,     0.84133,      0.8413,     0.84127,     0.84203,     0.84289,     0.84375,     0.84461,     0.84486,     0.84573,      0.8466,      0.8468,     0.84709,     0.84739,     0.84768,     0.84797,     0.84826,\n",
       "            0.84856,     0.84885,     0.84914,     0.84943,     0.84973,     0.85002,     0.85014,     0.84999,     0.84983,     0.84968,     0.84976,     0.85012,     0.85047,     0.85083,     0.85118,     0.85154,      0.8519,     0.85225,     0.85261,     0.85296,     0.85435,     0.85614,     0.85648,\n",
       "            0.85638,     0.85628,     0.85618,     0.85608,     0.85598,     0.85587,     0.85575,     0.85564,     0.85553,     0.85542,      0.8552,      0.8549,     0.85468,     0.85452,     0.85437,     0.85421,      0.8548,     0.85572,     0.85664,     0.85755,     0.85847,      0.8594,     0.86032,\n",
       "            0.86124,     0.86121,     0.86106,     0.86091,     0.86076,     0.86182,     0.86288,     0.86395,     0.86424,     0.86394,     0.86501,      0.8669,     0.86779,     0.86819,      0.8686,       0.869,      0.8694,      0.8698,      0.8702,      0.8706,     0.87101,     0.87113,     0.87085,\n",
       "               0.87,     0.86971,     0.86953,     0.86947,     0.86941,     0.86935,     0.86929,     0.86923,     0.86917,      0.8691,     0.86904,     0.86807,     0.86906,     0.87004,     0.87102,     0.87177,     0.87377,     0.87878,     0.87841,     0.87812,     0.87784,     0.87774,     0.87764,\n",
       "            0.87755,     0.87745,     0.87736,     0.87702,     0.87977,     0.88462,     0.88434,     0.88419,     0.88409,     0.88399,     0.88389,     0.88379,     0.88367,     0.88354,      0.8834,     0.88326,     0.88315,     0.88309,     0.88303,     0.88296,      0.8829,     0.88284,     0.88278,\n",
       "            0.88271,     0.88265,     0.88252,     0.88236,      0.8822,     0.88258,     0.88472,     0.88643,     0.88705,     0.88767,     0.88829,      0.8889,     0.88952,     0.89014,     0.88983,     0.88956,     0.88929,     0.88901,      0.8888,     0.88864,     0.88849,     0.88833,     0.88817,\n",
       "            0.88801,     0.88785,     0.88753,     0.88721,     0.88705,     0.88689,     0.88672,     0.88605,     0.88594,     0.88584,     0.88573,     0.88563,     0.88549,     0.88532,     0.88516,     0.88499,     0.88482,     0.88465,     0.88448,     0.88884,     0.88875,     0.88867,     0.88859,\n",
       "             0.8885,     0.88842,     0.88834,      0.8896,     0.89115,     0.89269,     0.89496,      0.8973,     0.89709,     0.89673,     0.89533,     0.89774,     0.89999,     0.89981,     0.89963,     0.90371,     0.90344,     0.90319,     0.90301,     0.90283,     0.90263,     0.90236,     0.90212,\n",
       "            0.90193,     0.90175,     0.90096,     0.90058,     0.90073,     0.90152,     0.90232,     0.90311,      0.9039,     0.90469,     0.90487,      0.9046,     0.90902,      0.9089,     0.90878,     0.90866,     0.91275,     0.91258,      0.9124,     0.91165,      0.9113,     0.90994,     0.90967,\n",
       "            0.91133,     0.91321,     0.91509,     0.91481,     0.91445,     0.91358,     0.91345,     0.91333,     0.91321,     0.91309,     0.91378,     0.91574,      0.9177,     0.91798,      0.9177,     0.91761,     0.91752,     0.91743,     0.91734,     0.91725,     0.91774,     0.91908,     0.92042,\n",
       "            0.92176,     0.92307,      0.9229,     0.92273,     0.92207,       0.922,     0.92192,     0.92185,     0.92177,      0.9217,     0.92162,     0.92096,      0.9206,     0.92036,     0.92014,     0.91933,     0.91896,     0.91802,     0.93047,     0.93027,     0.93007,     0.92924,     0.92838,\n",
       "            0.92804,     0.92783,     0.92762,     0.92731,     0.92695,     0.92658,     0.92608,     0.92509,      0.9242,     0.92406,     0.92391,     0.92376,     0.92352,     0.92312,     0.92226,     0.92201,     0.92176,     0.92151,     0.92125,     0.92062,     0.92018,     0.92647,     0.92598,\n",
       "            0.92674,     0.94114,     0.94094,     0.94073,     0.94043,     0.93907,     0.93885,     0.93863,     0.93759,      0.9424,     0.94594,     0.94851,     0.95107,     0.95363,     0.95349,     0.95282,     0.95252,     0.95234,     0.95228,     0.95221,     0.95214,     0.95208,     0.95201,\n",
       "            0.95194,     0.95157,     0.95061,      0.9501,     0.94921,     0.94839,     0.94821,     0.94802,     0.94769,      0.9472,     0.94682,     0.94652,     0.94623,     0.94593,     0.94564,     0.94543,     0.94523,     0.94502,     0.94477,     0.94452,     0.94367,     0.94345,     0.94323,\n",
       "              0.942,      0.9413,     0.94103,     0.94085,     0.94067,     0.94049,     0.93941,     0.93903,     0.93796,     0.93765,     0.93707,     0.93542,     0.94695,     0.94549,     0.94419,     0.94379,     0.94329,     0.95581,     0.95547,     0.95513,     0.95478,      0.9541,     0.96647,\n",
       "            0.96832,     0.98226,     0.98371,     0.98328,     0.98317,     0.98305,     0.98275,     0.98245,     0.98223,     0.98201,     0.98179,     0.98156,     0.98089,     0.99406,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.98062,     0.98062,     0.96899,     0.96899,     0.96899,     0.96512,     0.96512,     0.96512,     0.96124,     0.95736,     0.95736,     0.95736,     0.95736,     0.95736,     0.95349,     0.95349,     0.94961,     0.94961,     0.94961,     0.94961,     0.94961,     0.94961,     0.94961,\n",
       "            0.94961,     0.94961,     0.94961,     0.94961,     0.94961,     0.94961,     0.94961,     0.94574,     0.94574,     0.94186,     0.94186,     0.94186,     0.94186,     0.94186,     0.94186,     0.94186,     0.94186,     0.94186,     0.94186,     0.94186,     0.94186,     0.94186,     0.94186,\n",
       "            0.94186,     0.94186,     0.94186,     0.94186,     0.94186,     0.94186,     0.94186,     0.94186,     0.94047,     0.93887,     0.93798,     0.93798,     0.93757,     0.93455,     0.93411,     0.93411,     0.93411,     0.93411,     0.93411,     0.93411,     0.93411,     0.93411,     0.93411,\n",
       "            0.93411,     0.93411,     0.93411,     0.93411,     0.93411,     0.93023,     0.93023,     0.93023,     0.93023,     0.93023,     0.93023,     0.93023,     0.93023,     0.93023,     0.93023,     0.93023,     0.93023,     0.93023,     0.93023,     0.92962,      0.9284,     0.92717,     0.92636,\n",
       "            0.92636,     0.92636,     0.92636,     0.92636,     0.92636,     0.92636,     0.92636,     0.92541,     0.92264,     0.92248,     0.92248,      0.9186,      0.9186,      0.9186,      0.9186,      0.9186,      0.9186,      0.9186,      0.9186,     0.91473,     0.91473,     0.91473,     0.91473,\n",
       "            0.91473,     0.91473,     0.91473,     0.91473,     0.91473,     0.91473,     0.91473,     0.91473,     0.91473,     0.91473,     0.91471,     0.91085,     0.91085,     0.91085,     0.91085,     0.91085,     0.90958,     0.90813,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,\n",
       "            0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90698,     0.90675,     0.90548,     0.90421,      0.9023,     0.89922,     0.89922,     0.89922,     0.89922,     0.89922,\n",
       "            0.89922,     0.89922,     0.89922,     0.89922,     0.89922,     0.89922,     0.89922,     0.89922,     0.89922,     0.89922,     0.89922,     0.89922,     0.89922,     0.89922,     0.89922,     0.89922,     0.89922,     0.89809,     0.89535,     0.89535,     0.89535,     0.89535,     0.89535,\n",
       "            0.89347,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,\n",
       "            0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,\n",
       "            0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,\n",
       "            0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89147,     0.89131,     0.89089,     0.89047,     0.89005,     0.88963,     0.88922,      0.8888,     0.88838,     0.88796,      0.8876,\n",
       "             0.8876,      0.8876,      0.8876,      0.8876,      0.8876,      0.8876,      0.8876,      0.8876,      0.8876,      0.8876,     0.88748,     0.88668,     0.88589,     0.88509,      0.8843,     0.88372,     0.88372,     0.88372,     0.88372,     0.88372,     0.88372,     0.88372,     0.88372,\n",
       "            0.88372,     0.88372,     0.88372,     0.88372,     0.88372,     0.88372,     0.88372,     0.88372,     0.88372,     0.88372,     0.88365,     0.88331,     0.88298,     0.88265,     0.88232,     0.88199,     0.88166,     0.88133,       0.881,     0.88067,     0.88033,        0.88,     0.87984,\n",
       "            0.87984,     0.87984,     0.87984,     0.87984,     0.87984,     0.87984,     0.87828,     0.87601,     0.87597,     0.87591,     0.87571,     0.87551,     0.87531,     0.87511,     0.87491,     0.87471,     0.87451,      0.8743,      0.8741,      0.8739,      0.8737,      0.8735,      0.8733,\n",
       "             0.8731,      0.8729,     0.87269,     0.87249,     0.87229,     0.87209,     0.87209,     0.87209,     0.87209,     0.87197,     0.87161,     0.87124,     0.87088,     0.87052,     0.87016,      0.8698,     0.86944,     0.86908,     0.86872,     0.86835,     0.86699,       0.865,     0.86405,\n",
       "            0.86362,      0.8632,     0.86277,     0.86234,     0.86191,     0.86148,     0.86105,     0.86062,     0.86036,      0.8602,     0.86004,     0.85988,     0.85972,     0.85956,      0.8594,     0.85924,     0.85908,     0.85892,     0.85876,      0.8586,     0.85844,     0.85828,     0.85811,\n",
       "            0.85795,     0.85779,     0.85763,     0.85747,     0.85731,     0.85715,     0.85699,     0.85683,     0.85667,     0.85638,     0.85596,     0.85554,     0.85513,     0.85471,     0.85429,     0.85387,     0.85345,     0.85304,     0.85271,     0.85271,     0.85271,     0.85271,     0.85271,\n",
       "            0.85271,     0.85271,     0.85271,     0.85244,     0.85203,     0.85163,     0.85122,     0.85081,      0.8504,        0.85,     0.84959,     0.84918,     0.84868,     0.84769,      0.8467,      0.8457,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,\n",
       "            0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,\n",
       "            0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84496,     0.84045,     0.83979,     0.83912,     0.83846,\n",
       "             0.8378,     0.83312,     0.83113,     0.82935,     0.82869,     0.82803,     0.82737,      0.8267,     0.82604,     0.82558,     0.82558,     0.82552,     0.82534,     0.82516,     0.82498,      0.8248,     0.82461,     0.82443,     0.82425,     0.82407,     0.82389,     0.82371,     0.82353,\n",
       "            0.82335,     0.82317,     0.82299,     0.82281,     0.82263,     0.82245,     0.82227,     0.82209,     0.82191,     0.82173,     0.82171,     0.82171,     0.82171,     0.82171,     0.81783,     0.81783,     0.81783,     0.81395,     0.81395,     0.81395,     0.81395,     0.81395,     0.81395,\n",
       "            0.81395,     0.81395,     0.81395,     0.81395,     0.81395,     0.81395,     0.81358,     0.81258,     0.81159,      0.8106,     0.81008,     0.81008,     0.81008,     0.81008,     0.81008,     0.81008,     0.81008,     0.81008,     0.81008,     0.81008,     0.81008,     0.81008,     0.80957,\n",
       "            0.80891,     0.80824,     0.80758,     0.80692,     0.80626,     0.80554,     0.80482,      0.8041,     0.80337,     0.80265,     0.80123,     0.79925,     0.79785,     0.79686,     0.79587,     0.79487,     0.79457,     0.79457,     0.79457,     0.79457,     0.79457,     0.79457,     0.79457,\n",
       "            0.79457,     0.79369,     0.79269,      0.7917,     0.79071,      0.7907,      0.7907,      0.7907,     0.78956,     0.78757,     0.78682,     0.78682,     0.78682,     0.78682,     0.78682,     0.78682,     0.78682,     0.78682,     0.78682,     0.78682,     0.78682,     0.78602,     0.78403,\n",
       "            0.77817,     0.77618,     0.77498,     0.77457,     0.77415,     0.77373,     0.77331,     0.77289,     0.77247,     0.77206,     0.77164,     0.76357,     0.76357,     0.76357,     0.76357,     0.75969,     0.75969,     0.75868,     0.75603,     0.75399,       0.752,      0.7513,     0.75064,\n",
       "            0.74997,     0.74931,     0.74865,     0.74419,     0.74419,      0.7429,     0.74091,     0.73981,     0.73908,     0.73836,     0.73764,     0.73692,      0.7361,     0.73511,     0.73412,     0.73312,     0.73237,     0.73193,     0.73149,     0.73104,      0.7306,     0.73016,     0.72972,\n",
       "            0.72928,     0.72884,     0.72794,     0.72681,     0.72567,     0.72481,     0.72481,     0.72481,     0.72481,     0.72481,     0.72481,     0.72481,     0.72481,     0.72481,     0.72003,     0.71804,     0.71605,     0.71407,     0.71255,     0.71142,     0.71028,     0.70915,     0.70801,\n",
       "            0.70688,     0.70574,     0.70351,     0.70125,     0.70012,     0.69898,     0.69785,     0.69319,     0.69247,     0.69174,     0.69102,      0.6903,     0.68938,     0.68824,     0.68711,     0.68597,     0.68484,      0.6837,     0.68257,      0.6818,     0.68123,     0.68067,      0.6801,\n",
       "            0.67953,     0.67896,      0.6784,     0.67829,     0.67829,     0.67829,     0.67829,     0.67829,     0.67579,     0.67315,     0.66279,     0.66279,      0.6627,     0.66138,     0.66005,     0.65476,     0.65278,     0.65091,     0.64959,     0.64827,     0.64677,     0.64478,       0.643,\n",
       "            0.64168,     0.64035,     0.63464,       0.632,     0.62791,     0.62791,     0.62791,     0.62791,     0.62791,     0.62791,     0.62676,     0.62477,      0.6196,     0.61872,     0.61784,     0.61695,     0.60821,     0.60689,     0.60556,     0.59995,      0.5973,     0.58746,     0.58548,\n",
       "            0.58527,     0.58527,     0.58527,      0.5827,     0.58006,     0.57361,     0.57272,     0.57184,     0.57096,     0.57007,     0.56589,     0.56589,     0.56589,     0.56397,     0.56184,     0.56118,     0.56052,     0.55986,     0.55919,     0.55853,     0.55814,     0.55814,     0.55814,\n",
       "            0.55814,     0.55811,     0.55679,     0.55547,     0.55034,     0.54977,      0.5492,     0.54863,     0.54807,      0.5475,     0.54693,     0.54194,     0.53929,     0.53749,      0.5359,     0.53005,      0.5274,     0.52088,     0.51869,      0.5171,     0.51551,     0.50899,     0.50247,\n",
       "            0.49989,      0.4983,     0.49671,     0.49446,     0.49181,     0.48916,     0.48558,      0.4787,     0.47261,     0.47161,     0.47062,     0.46963,     0.46804,     0.46539,     0.45981,     0.45822,     0.45664,     0.45505,     0.45341,      0.4495,     0.44685,     0.43955,     0.43638,\n",
       "            0.43411,     0.43384,     0.43226,     0.43067,     0.42831,     0.41819,      0.4166,     0.41501,     0.40758,     0.40698,     0.39922,     0.39922,     0.39922,     0.39922,      0.3973,     0.39142,     0.38877,     0.38728,     0.38671,     0.38615,     0.38558,     0.38501,     0.38444,\n",
       "            0.38388,     0.38083,     0.37298,     0.36901,     0.36222,     0.35614,     0.35482,     0.35349,     0.35108,     0.34768,     0.34504,     0.34303,     0.34104,     0.33906,     0.33712,     0.33579,     0.33447,     0.33311,     0.33152,     0.32993,     0.32465,     0.32333,       0.322,\n",
       "            0.31474,     0.31077,     0.30926,     0.30826,     0.30727,     0.30628,     0.30049,      0.2985,     0.29303,     0.29144,     0.28858,     0.28073,     0.27676,     0.26891,     0.26231,     0.26033,     0.25789,     0.25151,     0.24952,     0.24754,     0.24555,     0.24169,     0.24031,\n",
       "            0.23693,     0.23643,     0.23405,     0.22799,      0.2264,     0.22481,     0.22084,     0.21693,     0.21428,     0.21164,     0.20899,     0.20634,     0.19895,      0.1938,     0.18964,     0.18831,     0.18699,     0.18489,     0.18134,     0.17869,     0.16716,     0.16047,     0.15564,\n",
       "             0.1506,     0.14999,     0.14938,     0.14876,     0.14815,     0.14754,     0.14316,     0.14051,     0.13494,     0.13381,     0.13267,     0.12618,     0.11483,     0.11284,     0.10737,      0.1034,     0.10033,    0.099001,    0.097677,     0.09526,    0.092445,     0.09112,    0.089796,\n",
       "           0.081217,    0.076988,    0.075995,    0.075002,    0.074009,    0.068619,    0.061881,    0.061087,    0.060292,    0.059497,    0.058703,    0.057809,    0.056674,    0.055539,    0.054404,    0.053897,    0.053479,    0.053061,    0.052642,    0.052224,    0.051806,    0.051388,     0.05097,\n",
       "           0.050551,     0.04614,    0.045529,    0.044917,    0.044306,    0.043695,    0.043084,    0.042211,    0.040622,    0.039033,    0.033787,    0.032463,    0.031138,    0.030212,    0.029329,    0.028446,    0.027563,    0.026455,     0.02513,    0.023806,    0.019252,    0.017927,    0.016603,\n",
       "           0.014154,    0.010273,   0.0082864,   0.0069222,   0.0057871,   0.0046519,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: 0.5489630736867184\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,\n",
       "           0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,\n",
       "           0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,\n",
       "           0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204,     0.51204])\n",
       "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush', 80: 'building'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.8113172966857725, 'metrics/recall(B)': 0.8833146777268225, 'metrics/mAP50(B)': 0.8812421058428325, 'metrics/mAP50-95(B)': 0.5120431812249279, 'fitness': 0.5489630736867184}\n",
       "save_dir: WindowsPath('runs/detect/train48')\n",
       "speed: {'preprocess': 1.500270196369716, 'inference': 28.35656063897269, 'loss': 0.0, 'postprocess': 2.268484660557338}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_test.train(data='D:/LNU/6.1/Course/Test3/Yolov8_main/content/building_Data/test.yaml', epochs=50, batch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "821095bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush', 80: 'building'}\n"
     ]
    }
   ],
   "source": [
    "# print(len(model_test.names))\n",
    "# dict_classes = model_test.model.names\n",
    "# print(dict_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b1bf40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# torch.save(model_test, \"D:/LNU/6.1/Course/Test3/Yolov8_main/saved_models/yolov8_50_epoch_v2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "182cf1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_scripted = torch.jit.script(model_test)\n",
    "# model_scripted.save(\"D:/LNU/6.1/Course/Test3/Yolov8_main/saved_models/yolov8_50_epoch_v2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899fe0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.jit.load(\"D:/LNU/6.1/Course/Test3/Yolov8_main/saved_models/yolov8_50_epoch_v2.pt\")\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3710d7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb899e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
